{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is currently for converting Type 1 Input, Type 3 Output (Type (1,3) or Type 3 Labeling) data spreadsheets into Type 1 Input, Type 5 Output (Type (1,5) or Type 5 Labeling) data spreadsheets. In the code, \"input_label_type\" refers to the initial spreadsheet's labeling scheme, and \"output_label_type\" refers to the produced spreadsheet's labeling scheme.\n",
    "\n",
    "You will have to MANUALLY remove the column/row labels in the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# I would use jdc for splitting the class into readable sections,\n",
    "    # but the author of that library hasn't provided a license\n",
    "    # in their GitHub repository.\n",
    "    # I have opened an issue on the GitHub requesting they add a license. \n",
    "    # If they do not see and respond to it, I may use\n",
    "        # \"Class Converter(Converter)\" to accomplish splitting\n",
    "        # the code into different cells for readability\n",
    "#import jdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Converter():\n",
    "    # tuple to reduce dynamic changes possible\n",
    "    FILE_SPECIFIERS = (\n",
    "        \"Type\",\n",
    "        \"WithClassNum\",\n",
    "        \"Freq\",\n",
    "        \"BufferType\",\n",
    "        \"BufferNum\",\n",
    "        \"UserType\",\n",
    "        \"UserID\"\n",
    "    )\n",
    "    print(len(FILE_SPECIFIERS))\n",
    "\n",
    "    # These three are ndarrays of tags and descriptors you can pull from if needed.\n",
    "        # If they are commented, they are not currently in use.\n",
    "        # CLASS_TAGS will be used to test for certain types of classes, so later we don't have to \n",
    "            # manually type in the index of each applicable class, reducing potential for mistakes.\n",
    "        # BEGINNING_DESCRIPTORS and ENDING_DESCRIPTORS will be used in file names.\n",
    "    # The \"<School Year>\" ending descriptor is supposed to later be dynamically replaced by something like \"23-24\", and\n",
    "        # \"<Semester>\" is supposed to later be dynamically replaced by either \"Fall\", \"Spring\", or \"Summer\".\n",
    "        # If it is across multiple school years, use the start and end years.\n",
    "            # For example, if it was from 23-24 to 26-27, use \"23-27\".\n",
    "        # If it is across multiple semesters, just don't include the semester ending descriptor\n",
    "    \n",
    "    # these are explicitly defined to lower the chance for typed mistakes\n",
    "        # while also allowing descriptive use\n",
    "    exercise_tag = \"Exercise\"\n",
    "    nonexercise_tag = \"Non-Exercise\"\n",
    "    ambiguous_exercise_tag = \"Ambiguous Exercise\" # this would be used for things that may or may not be part of an exercise (certain stationary classes)\n",
    "    full_tag = \"Full\"\n",
    "    border_tag = \"Border\" # Start or End -- different to \"Boundary\" if used\n",
    "    start_tag = \"Start\"\n",
    "    end_tag = \"End\"\n",
    "    forward_lean_tag = \"Forward Lean\"\n",
    "    forward_knee_lean_tag = \"Forward Knee Lean\"\n",
    "    forward_table_lean_tag = \"Forward Table Lean\"\n",
    "    lateral_lean_tag = \"Lateral Lean\"\n",
    "    lateral_push_lean_tag = \"Lateral Push Lean\"\n",
    "    lateral_hold_lean_tag = \"Lateral Hold Lean\"\n",
    "    left_lean_tag = \"Left Lean\"\n",
    "    right_lean_tag = \"Right Lean\"\n",
    "    pushup_tag = \"Pushup\"\n",
    "    #boundary_tag = \"Boundary\" # This might later be used for the edges of data files to note where they are glued together\n",
    "    other_tag = \"Other\"\n",
    "    stationary_tag = \"Stationary\"\n",
    "    nonstationary_tag = \"Non-Stationary\"\n",
    "    ambiguous_stationary_tag = \"Ambiguous Stationary\" # (\"Other\" class that also contains Stationary portions would use this)\n",
    "\n",
    "    CLASS_TAGS = {\n",
    "        exercise_tag,\n",
    "        nonexercise_tag,\n",
    "        ambiguous_exercise_tag,\n",
    "        full_tag,\n",
    "        border_tag,\n",
    "        start_tag,\n",
    "        end_tag,\n",
    "        forward_lean_tag,\n",
    "        forward_knee_lean_tag,\n",
    "        forward_table_lean_tag,\n",
    "        lateral_lean_tag,\n",
    "        lateral_push_lean_tag,\n",
    "        lateral_hold_lean_tag,\n",
    "        left_lean_tag,\n",
    "        right_lean_tag,\n",
    "        pushup_tag,\n",
    "        other_tag,\n",
    "        stationary_tag,\n",
    "        nonstationary_tag,\n",
    "        ambiguous_stationary_tag\n",
    "    }\n",
    "    # BEGINNING_DESCRIPTORS = np.array([\"COMBINED\"])\n",
    "    # ENDING_DESCRIPTORS = np.array([\"Motion-Sessions\", \"<School Year>\", \"<Semester>\"])\n",
    "\n",
    "\n",
    "    # file specification list:\n",
    "    # NOTE: These should appear in order for the code to work\n",
    "        # (though the code will run well even if some are missing)\n",
    "    # NOTE: 0 should (almost) always be treated as the unknown value.\n",
    "        # if you add something that uses the value 0, consider what\n",
    "        # might need changed in the code to make it work\n",
    "\n",
    "        # (1) Type (ClassType, LabelType, OutputType):\n",
    "            # This specifies how the data is stored.\n",
    "            # USAGE: This appears ONLY in Labeled specifier lists\n",
    "            # INFO: The current types' definitions can be found in the files\n",
    "                # DataTranslations.docx\n",
    "                # DataCollectionAndLabelingTechniquesDocumentation.docx\n",
    "\n",
    "        # (2) WithClassNum: this specifies how many output classes a type has\n",
    "            # so one immediately knows without having to look it up.\n",
    "            # USAGE: This appears ONLY in Labeled specifier lists\n",
    "            # NOTE: WithClassNum should not change separately to Type.\n",
    "                # This is just here to better convey classification info\n",
    "\n",
    "        # (3) Freq: this specifies the frequency the data collector\n",
    "            # was set to when collecting that set of data.\n",
    "            # USAGE: This appears BOTH in Labeled and Unlabeled specifier lists\n",
    "            # NOTE: there are currently no functions to convert between frequencies\n",
    "                # as we have only used one frequency so far,\n",
    "                # and as we will have to test whether the values change with\n",
    "                # frequency in some way due to how the measurements are taken\n",
    "            # NOTE: if you ever change the Freq of the file, be sure to adjust\n",
    "                # BufferNum accordingly\n",
    "\n",
    "        # (4) BufferType: this specifies how and where buffers are added to labeled data.\n",
    "            # USAGE: This appears ONLY in Labeled specifier lists\n",
    "            # NOTE: there are currently no functions to convert between buffer types\n",
    "                # as there is only one buffer type.\n",
    "\n",
    "        # (5) BufferNum: this specifies how many measurements before and after\n",
    "            # certain activities should be labeled the same as that activity\n",
    "            # USAGE: This appears ONLY in Labeled specifier lists\n",
    "\n",
    "        # (6) UserType: this states who collected the data --\n",
    "            # us researchers (marked as 1) or manual wheelchair users (marked as 2).\n",
    "            # Data from researchers who are also manual wheelchair users should be\n",
    "            # marked as 3. Data combined from files marked with ((1 and/or 3) AND 2)\n",
    "            # should be marked as 4 (combining less-biased data with more-biased data)\n",
    "            # USAGE: This appears BOTH in Labeled and Unlabeled specifier lists\n",
    "            # NOTE: Unmarked files are automatically labeled with a 0 when passing\n",
    "                # through the converter and must be manually remarked. If you are\n",
    "                # unsure which mark is correct, leave it as 0 and treat it as a 1\n",
    "                # when using the data\n",
    "    \n",
    "        # (7) UserID: This allows us to loosely tell which data files were made by the\n",
    "            # same person. The UserID may be allowed to change occasionally if keeping\n",
    "            # it the same might be unfeasible. UserID of 0 means unknown.\n",
    "            # USAGE: This appears BOTH in Labeled and Unlabeled specifier lists.\n",
    "            # INFO: Researchers' UserIDs will be stored in [not-yet-created-document name]\n",
    "            # NOTE: UserID should NOT be stored alongside and with correspondence to\n",
    "                # the user's personal information unless Dr. Fu (or other person heading\n",
    "                # the project if that changes) says otherwise as that may have legal\n",
    "                # implications. In other words, data we store should NOT be directly\n",
    "                # traceable back to the user who created that data (unless it's data\n",
    "                # we made ourselves)\n",
    "    \n",
    "        # (#) Labeled OR Unlabeled: This tells us whether the file has been labeled yet.\n",
    "            # An unlabeled file will only have the Freq, UserType, and UserID specifiers\n",
    "            # This Converter is not equipped to detect whether a file is Labeled or \n",
    "                # Unlabeled and instead treats all as Labeled\n",
    "\n",
    "\n",
    "    # Tuples and Dictionaries describing Type and WithClassNum (and, later, InputType)\n",
    "    NUM_OF_LABEL_TYPES = 5\n",
    "    VALID_TYPE_CONVERSIONS = (\n",
    "        (3, 5),\n",
    "    )\n",
    "    OVERRIDE_TYPE_VALIDATION = (\n",
    "        # This is here only for conversions that \n",
    "            # fail validate_class_type_conversion() but not for simple reasons\n",
    "            # (simple reasons like accidentally choosing the wrong input/output types\n",
    "            # or not listing the correct values in the below dictionaries)\n",
    "        # If you add an entry here you may have to change logic of other parts of the code\n",
    "            # for instance if the number of columns of the output spreadsheet will be more\n",
    "            # than the input spreadsheet, you may have to change the dataframe.drop line at the end\n",
    "    )\n",
    "\n",
    "    \n",
    "    LIST_OF_CLASSES_AND_TAGS_PER_TYPE = {\n",
    "        1: {\n",
    "            # Type 1, Class 1\n",
    "            \"Forward Lean\": (\n",
    "                exercise_tag,\n",
    "                full_tag,\n",
    "                forward_lean_tag,\n",
    "                ambiguous_stationary_tag\n",
    "            ),\n",
    "            # Type 1, Class 2\n",
    "            \"Left Lean\": (\n",
    "                exercise_tag,\n",
    "                full_tag,\n",
    "                lateral_lean_tag,\n",
    "                left_lean_tag,\n",
    "                ambiguous_stationary_tag\n",
    "            ),\n",
    "            # Type 1, Class 3\n",
    "            \"Right Lean\": (\n",
    "                exercise_tag,\n",
    "                full_tag,\n",
    "                lateral_lean_tag,\n",
    "                right_lean_tag,\n",
    "                ambiguous_stationary_tag\n",
    "            ),\n",
    "            # Type 1, Class 4\n",
    "            \"Pushup\": (\n",
    "                exercise_tag,\n",
    "                full_tag,\n",
    "                pushup_tag,\n",
    "                ambiguous_stationary_tag\n",
    "            ),\n",
    "            # Type 1, Class 5\n",
    "            \"Other\": (\n",
    "                nonexercise_tag,\n",
    "                other_tag,\n",
    "                ambiguous_stationary_tag\n",
    "            )\n",
    "        },\n",
    "        2: {\n",
    "            # Type 2, Class 1\n",
    "            \"Forward Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                forward_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 2, Class 2\n",
    "            \"Forward Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                forward_lean_tag,\n",
    "                nonstationary_tag,\n",
    "            ),\n",
    "            # Type 2, Class 3\n",
    "            \"Left Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                lateral_lean_tag,\n",
    "                left_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 2, Class 4\n",
    "            \"Left Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                lateral_lean_tag,\n",
    "                left_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 2, Class 5\n",
    "            \"Right Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                lateral_lean_tag,\n",
    "                right_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 2, Class 6\n",
    "            \"Right Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                lateral_lean_tag,\n",
    "                right_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 2, Class 7\n",
    "            \"Pushup Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                pushup_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 2, Class 8\n",
    "            \"Pushup End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                pushup_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 2, Class 9\n",
    "            \"Stationary\": (\n",
    "                ambiguous_exercise_tag,\n",
    "                stationary_tag\n",
    "            ),\n",
    "            # Type 2, Class 10\n",
    "            \"Other\": (\n",
    "                nonexercise_tag,\n",
    "                other_tag,\n",
    "                nonstationary_tag\n",
    "            )\n",
    "        },\n",
    "        3: {\n",
    "            # Type 3, Class 1\n",
    "            \"Forward Knee Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                forward_lean_tag,\n",
    "                forward_knee_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 2\n",
    "            \"Forward Knee Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                forward_lean_tag,\n",
    "                forward_knee_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 3\n",
    "            \"Forward Table Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                forward_lean_tag,\n",
    "                forward_table_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 4\n",
    "            \"Forward Table Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                forward_lean_tag,\n",
    "                forward_table_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 5\n",
    "            \"Left Push Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                lateral_lean_tag,\n",
    "                left_lean_tag,\n",
    "                lateral_push_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 6\n",
    "            \"Left Push Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                lateral_lean_tag,\n",
    "                left_lean_tag,\n",
    "                lateral_push_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 7\n",
    "            \"Left Hold Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                lateral_lean_tag,\n",
    "                left_lean_tag,\n",
    "                lateral_hold_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 8\n",
    "            \"Left Hold Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                lateral_lean_tag,\n",
    "                left_lean_tag,\n",
    "                lateral_hold_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 9\n",
    "            \"Right Push Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                lateral_lean_tag,\n",
    "                right_lean_tag,\n",
    "                lateral_push_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 10\n",
    "            \"Right Push Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                lateral_lean_tag,\n",
    "                right_lean_tag,\n",
    "                lateral_push_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 11\n",
    "            \"Right Hold Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                lateral_lean_tag,\n",
    "                right_lean_tag,\n",
    "                lateral_hold_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 12\n",
    "            \"Right Hold Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                lateral_lean_tag,\n",
    "                right_lean_tag,\n",
    "                lateral_hold_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 13\n",
    "            \"Pushup Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                pushup_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 14\n",
    "            \"Pushup End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                pushup_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 15\n",
    "            \"Stationary\": (\n",
    "                ambiguous_exercise_tag,\n",
    "                stationary_tag\n",
    "            ),\n",
    "            # Type 3, Class 16\n",
    "            \"Other\": (\n",
    "                nonexercise_tag,\n",
    "                other_tag,\n",
    "                nonstationary_tag\n",
    "            )\n",
    "        },\n",
    "        4: {\n",
    "            # Type 4, Class 1\n",
    "            \"Forward Lean\": (\n",
    "                exercise_tag,\n",
    "                full_tag,\n",
    "                forward_lean_tag,\n",
    "                ambiguous_stationary_tag\n",
    "            ),\n",
    "            # Type 4, Class 2\n",
    "            \"Lateral Lean\": (\n",
    "                exercise_tag,\n",
    "                full_tag,\n",
    "                lateral_lean_tag,\n",
    "                ambiguous_stationary_tag\n",
    "            ),\n",
    "            # Type 4, Class 3\n",
    "            \"Pushup\": (\n",
    "                exercise_tag,\n",
    "                full_tag,\n",
    "                pushup_tag,\n",
    "                ambiguous_stationary_tag\n",
    "            ),\n",
    "            # Type 4, Class 4\n",
    "            \"Other\": (\n",
    "                nonexercise_tag,\n",
    "                other_tag,\n",
    "                ambiguous_stationary_tag\n",
    "            )\n",
    "        },\n",
    "        5: {\n",
    "            # Type 5, Class 1\n",
    "            \"Forward Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                forward_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 5, Class 2\n",
    "            \"Forward Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                forward_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 5, Class 3\n",
    "            \"Lateral Lean Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                lateral_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 5, Class 4\n",
    "            \"Lateral Lean End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                lateral_lean_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 5, Class 5\n",
    "            \"Pushup Start\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                start_tag,\n",
    "                pushup_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 5, Class 6\n",
    "            \"Pushup End\": (\n",
    "                exercise_tag,\n",
    "                border_tag,\n",
    "                end_tag,\n",
    "                pushup_tag,\n",
    "                nonstationary_tag\n",
    "            ),\n",
    "            # Type 5, Class 7\n",
    "            \"Stationary\": (\n",
    "                ambiguous_exercise_tag,\n",
    "                stationary_tag\n",
    "            ),\n",
    "            # Type 5, Class 8\n",
    "            \"Other\": (\n",
    "                nonexercise_tag,\n",
    "                other_tag,\n",
    "                nonstationary_tag\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "\n",
    "    NUM_OF_INPUTS_PER_TYPE = {\n",
    "        # if any of these are ever not 3, switch code will need to be different\n",
    "            # between two different numbers of inputs\n",
    "        1: 3,\n",
    "        2: 3,\n",
    "        3: 3,\n",
    "        4: 3,\n",
    "        5: 3\n",
    "    }\n",
    "    NUM_OF_CLASSES_PER_TYPE = {\n",
    "        1: 5,\n",
    "        2: 10,\n",
    "        3: 16,\n",
    "        4: 4,\n",
    "        5: 8\n",
    "    }\n",
    "    # if 1, the ouput is a one-hot vector\n",
    "    NUM_OF_OUTPUTS_PER_TYPE = {\n",
    "        1: 1,\n",
    "        2: 1,\n",
    "        3: 1,\n",
    "        4: 1,\n",
    "        5: 1\n",
    "    }\n",
    "\n",
    "\n",
    "    # Tuples and dictionaries describing BufferType and BufferNum\n",
    "    NUM_OF_BUFFER_TYPES = 1\n",
    "    # Currently these do nothing. If we later change how we want the buffers to function\n",
    "        # (not the length of the buffers but which buffers overlap into other classes),\n",
    "        # we will be able to do so using this\n",
    "    VALID_BUFFER_TYPE_CONVERSIONS = ()\n",
    "    OVERRIDE_BUFFER_TYPE_VALIDATION = (\n",
    "        # This is here only for BufferType conversions that \n",
    "            # fail validate_buffer_type_conversion() but not for simple reasons\n",
    "            # (simple reasons like accidentally choosing the wrong input/output types\n",
    "            # or not listing the correct values in the above dictionaries)\n",
    "        # If you add an entry here you may have to change logic of other parts of the code\n",
    "    )\n",
    "\n",
    "    # each buffer type has a dictionary;\n",
    "        # the keys of each dictionary have precedence over the values;\n",
    "        # rules (key-value pairs) listed sooner have priority over later rules\n",
    "    PRECEDENCE_OF_TAGS_PER_BUFFER_TYPE = {\n",
    "        1: {\n",
    "            # exercises should have precedence over \"Other\" and \"Stationary\"\n",
    "            exercise_tag: (nonexercise_tag, ambiguous_exercise_tag),\n",
    "            # we actually don't want the following line because then in Type 3 and Type 5,\n",
    "                # Stationary would have precedence over Other (which would be incorrect)\n",
    "            #ambiguous_exercise_tag: (nonexercise_tag,) # the comma here is to make it a tuple #\n",
    "            # \"Other\" should have precedence over \"Stationary\"\n",
    "            nonstationary_tag: (stationary_tag, ambiguous_stationary_tag)\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, labeled_data_file):\n",
    "        # if not all(n == Converter.NUM_OF_LABEL_TYPES for n in (len(Converter.NUM_OF_INPUTS_PER_TYPE), len(Converter.NUM_OF_CLASSES_PER_TYPE), len(Converter.NUM_OF_OUTPUTS_PER_TYPE))):\n",
    "        #     print(\"Converter is not usable if defining dictionaries do not match corresponding dictionaries in size.\")\n",
    "        #     print(\"Fix and rerun the code to use the converter\")\n",
    "        #     return\n",
    "        self.input_directory, self.input_beginning_descriptors, self.input_file_name, self.input_ending_descriptors, self.input_file_extension, self.input_specifiers = Converter.read_file_name(labeled_data_file)\n",
    "        self.output_label_type = -1\n",
    "        self.output_freq = -1\n",
    "        self.output_buffer_type = -1\n",
    "        self.output_buffer_num = -1\n",
    "\n",
    "    \n",
    "\n",
    "    def validate_label_type_conversion(self, input_label_type, output_label_type):\n",
    "        # validating type values' and type dictionaries' consistency\n",
    "        # all label type dictionaries have the same length\n",
    "        can_use_dictionaries = all(n == Converter.NUM_OF_LABEL_TYPES for n in (len(Converter.NUM_OF_INPUTS_PER_TYPE), len(Converter.NUM_OF_CLASSES_PER_TYPE), len(Converter.NUM_OF_OUTPUTS_PER_TYPE)))\n",
    "        # these commented lines were made obsolete by the line following\n",
    "        # both label types are positive\n",
    "        #has_positive_types = input_label_type > 0 and output_label_type > 0\n",
    "        # both label types are greater than or equal to the number of different label types\n",
    "        #has_bounded_types = input_label_type <= Converter.NUM_OF_LABEL_TYPES and output_label_type <= Converter.NUM_OF_LABEL_TYPES\n",
    "        # both label types are valid types\n",
    "        #has_valid_types = has_positive_types and has_bounded_types\n",
    "        has_valid_types = input_label_type in np.arange(1, Converter.NUM_OF_LABEL_TYPES + 1) and output_label_type in np.arange(1, Converter.NUM_OF_LABEL_TYPES + 1)\n",
    "        # input_label_type matches self.input_label_type\n",
    "        matches_input_file = self.input_specifiers.get(\"Type\", -1) == input_label_type\n",
    "        # input_label_type corresponds to WithClassNum value stored in self\n",
    "        consistent_with_class_num = self.input_specifiers.get(\"WithClassNum\", -1) == Converter.NUM_OF_CLASSES_PER_TYPE[input_label_type]\n",
    "        # has valid values (compared to type dictionaries and the conversion file)\n",
    "        has_consistent_values = can_use_dictionaries and has_valid_types and matches_input_file and consistent_with_class_num\n",
    "\n",
    "        # validating conversion logic\n",
    "        # is a type conversion for which someone implemented the logic\n",
    "        is_listed = (input_label_type, output_label_type) in Converter.VALID_TYPE_CONVERSIONS #.get((input_label_type, output_label_type), False)\n",
    "        # is a logical input type conversion\n",
    "        is_not_to_more_inputs = Converter.NUM_OF_INPUTS_PER_TYPE.get(input_label_type, 0) >= Converter.NUM_OF_INPUTS_PER_TYPE.get(output_label_type, 1)\n",
    "        # is a logical output type conversion when only one class chosen at a time\n",
    "        is_to_fewer_classes = Converter.NUM_OF_CLASSES_PER_TYPE.get(input_label_type, 0) > Converter.NUM_OF_CLASSES_PER_TYPE.get(output_label_type, 0)\n",
    "        # may be logical output type conversion if we are converting from\n",
    "            # an output with a \"multi-hot\" vector to an input with a one-hot vector\n",
    "        input_is_not_one_hot_type = Converter.NUM_OF_OUTPUTS_PER_TYPE.get(input_label_type, 1) != 1\n",
    "        # all conversion logic between types is sound\n",
    "        has_valid_logic = is_listed and is_not_to_more_inputs and (is_to_fewer_classes or input_is_not_one_hot_type)\n",
    "\n",
    "        # allowing override\n",
    "        # the others are to keep someone from accidentally making a \"bad conversion,\"\n",
    "            # but this one is to allow more-complex conversions that are possible,\n",
    "            # given that someone manually listed the conversion in OVERRIDE_TYPE_VALIDATION\n",
    "        # this does not override the conversion if the file is incorrect or if the types are invalid\n",
    "        is_overridden = (input_label_type, output_label_type) in Converter.OVERRIDE_TYPE_VALIDATION #.get((input_label_type, output_label_type), False)\n",
    "\n",
    "        return has_consistent_values and (has_valid_logic or is_overridden)\n",
    "    \n",
    "\n",
    "    def validate_buffer_num_conversion(self, input_buffer_num, output_buffer_num):\n",
    "        # validate consistency\n",
    "        # both buffer nums are non-negative\n",
    "        has_nonnegative_buffer_nums = input_buffer_num >= 0 and output_buffer_num >= 0\n",
    "        # input_buffer_num matches self.input_buffer_num\n",
    "        matches_input_file = self.input_specifiers.get(\"BufferNum\", -1) == input_buffer_num\n",
    "        # BufferType is valid\n",
    "        has_valid_buffer_type = self.input_specifiers.get(\"BufferType\", 0) in np.arange(1, Converter.NUM_OF_BUFFER_TYPES + 1)\n",
    "        # combining\n",
    "        has_consistent_values = has_nonnegative_buffer_nums and matches_input_file and has_valid_buffer_type\n",
    "        # returning\n",
    "        return has_consistent_values\n",
    "    \n",
    "\n",
    "    def set_label_type_conversion(self, input_label_type, output_label_type):\n",
    "        #NOTE that types have not yet been implemented as tuple labels\n",
    "        if(not self.validate_label_type_conversion(input_label_type, output_label_type)):\n",
    "            print(f\"Current object/class definitions prohibit the conversion from Type {input_label_type} to Type {output_label_type}.\")\n",
    "            return\n",
    "        #self.input_label_type = input_label_type\n",
    "        self.output_label_type = output_label_type\n",
    "    \n",
    "\n",
    "    def set_buffer_num_conversion(self, input_buffer_num, output_buffer_num):\n",
    "        if(not self.validate_buffer_num_conversion(input_buffer_num, output_buffer_num)):\n",
    "            print(f\"Current object/class definitions prohibit the conversion from BufferNum {input_buffer_num} to BufferNum {output_buffer_num}.\")\n",
    "            return\n",
    "        #self.input_buffer_num = input_buffer_num\n",
    "        self.output_buffer_num = output_buffer_num\n",
    "        \n",
    "\n",
    "\n",
    "    # this returns:\n",
    "        # the input file's directory (where it is in the computer),\n",
    "        # the beginning descriptors (the file descriptors that come before the file specifiers),\n",
    "        # the file name (commented out code corrected it if it was missing any file specifiers,\n",
    "            # but this is functionality that could be -- and has been -- replaced by build_file_name)\n",
    "            # (the file name includes everything but the directory),\n",
    "        # the ending descriptors (the file descriptors that come after the file specifiers),\n",
    "        # the file's extension (the file type), and\n",
    "        # the values for all file specifiers (as a dict)\n",
    "            # (this does not yet include the \"Labeled\" or \"Unlabeled\" file specifiers)\n",
    "    def read_file_name(file_path):\n",
    "        specifier_values = {} #np.zeros((len(Converter.FILE_SPECIFIERS), 1))\n",
    "        beginning_descriptors = []\n",
    "        ending_descriptors = []\n",
    "        # at the start of each iteration (except the first),\n",
    "            # dash_index points to the dash just before the file specifier;\n",
    "            # by the end of each iteration, it points to the next dash\n",
    "        # rfind() finds the right-most instance;\n",
    "            # using dash_index, we separate the directory and the file name\n",
    "        separator_index = file_path.rfind('/')\n",
    "        file_directory = file_path[ : (separator_index + 1)]\n",
    "        print(file_directory)\n",
    "        # we initialize output_file_name like this in case it has some\n",
    "            # descriptors at the start of the file, before any file specifiers\n",
    "        temp_index = file_path.find(Converter.FILE_SPECIFIERS[0])\n",
    "        file_name = file_path[(separator_index + 1) : ] # used to be [(separator_index + 1) : temp_index]\n",
    "        #print(file_name)\n",
    "\n",
    "\n",
    "        # while we haven't reached the beginning of the file specifier list\n",
    "        while (separator_index + 1) < temp_index:\n",
    "            # separator_index_2 points to just before each descriptor,\n",
    "                # and separator_index points to just after\n",
    "            separator_index_2 = separator_index\n",
    "            separator_index = file_path.find('_', separator_index)\n",
    "            beginning_descriptors.append(file_path[(separator_index_2 + 1) : separator_index])\n",
    "\n",
    "\n",
    "        for fs in Converter.FILE_SPECIFIERS:\n",
    "            # ignore this comment\n",
    "            # if(i != 0): (since we already do this for the first iteration beforehand)\n",
    "            if fs != Converter.FILE_SPECIFIERS[0]:\n",
    "                temp_index = file_path.find(fs, separator_index)\n",
    "\n",
    "            # if temp_index is a substring of input_file_name\n",
    "            if temp_index >= 0:\n",
    "                # temp_index is the index of the start of the number value for the specifier\n",
    "                    # (we treat this as unrelated to dash_index in case the value has more than one digit)\n",
    "                temp_index += len(fs)\n",
    "                # we are guaranteed to have a dash after each file specifier;\n",
    "                    # this includes the last one since \"Labeled\" should be a final\n",
    "                    # file specifier with no value for every labeled data set.\n",
    "                    # \"Unlabeled\" may later be used, but code needs to change\n",
    "                separator_index = file_path.find('-', temp_index)\n",
    "                # this makes sure we get the full number\n",
    "                specifier_values[fs] = (int)(file_path[temp_index : separator_index])\n",
    "            else: #values[i] used to automatically stay 0\n",
    "                specifier_values[fs] = 0\n",
    "\n",
    "            #file_name += f'{fs}{specifier_values[fs]}-'\n",
    "\n",
    "        # THIS IS ONLY HERE BECAUSE WE ARE ASSUMING THE FILE IS LABELED;\n",
    "            # IF YOU ARE NOW PROCESSING UNLABELED FILES, ADJUST THIS\n",
    "        #file_name += 'Labeled'\n",
    "\n",
    "\n",
    "        # this line makes sure we keep track of the end of the file specifier section\n",
    "        temp_index = separator_index + len('Labeled')\n",
    "        # if there are no ending separators, separator_index_2 will be -1\n",
    "            # (I don't know what separator_index will be)\n",
    "        # if there is one ending separator, only separator_index will be -1.\n",
    "            # the next step will not change anything\n",
    "        # when we reach the last one normally, the separator_index will be -1.\n",
    "            # the next step will not change anything\n",
    "        # these two lines already prepare the first segment\n",
    "        separator_index_2 = file_path.find('_', separator_index)\n",
    "        separator_index = file_path.find('_', separator_index_2)\n",
    "        # if it found an underscore indicating ending descriptors\n",
    "        if(separator_index_2 > 0):\n",
    "            # we purposefully decide to flip the order of operation versus incrementation\n",
    "                # here as compared to the order of the beginning_descriptors reader\n",
    "            # while we haven't reached the extension of file_path\n",
    "            while file_path[separator_index_2] != '.':\n",
    "                # here, if we have found the last ending_descriptor,\n",
    "                    # the find function will not have found another\n",
    "                    # underscore, and will return -1 for separator_index,\n",
    "                    # but we do not want to include the extension\n",
    "                    # (.csv or the like)\n",
    "                if separator_index < 0:\n",
    "                    separator_index = file_path.find('.', separator_index_2)\n",
    "\n",
    "                ending_descriptors.append(file_path[(separator_index_2 + 1) : separator_index])\n",
    "                # separator_index_2 points to just before each descriptor,\n",
    "                    # and separator_index points to just after\n",
    "                separator_index_2 = separator_index\n",
    "                separator_index = file_path.find('_', separator_index)\n",
    "        else:\n",
    "            temp_index = file_path.find('.', temp_index)\n",
    "        \n",
    "\n",
    "        file_extension = file_path[separator_index_2 : ]\n",
    "\n",
    "\n",
    "        #file_name += file_path[(temp_index + 1) : ]\n",
    "        print(f'File name is \"{file_name}\".')\n",
    "        print(f'File name read as \"{Converter.build_file_name(specifier_values, beginning_descriptors, ending_descriptors, file_extension)}\".')\n",
    "        return file_directory, beginning_descriptors, file_name, ending_descriptors, file_extension, specifier_values\n",
    "    \n",
    "\n",
    "\n",
    "    # beginning_descriptors and ending_descriptors do not include the separating underscores;\n",
    "        # ending_descriptors do not include the value-less file specifier \"Labeled\";\n",
    "        # both should be numpy ARRAYS (though they can be empty)\n",
    "    def build_file_name(file_specifier_values, beginning_descriptors = [], ending_descriptors = [], file_extension = '.csv'):\n",
    "        # this ensures the file name is not empty so we can add to it\n",
    "        file_name = ''\n",
    "\n",
    "        for bd in beginning_descriptors:\n",
    "            file_name += bd + '_'\n",
    "\n",
    "        # this set of lines will need to be changed if we ever want to use this function\n",
    "            # on Unlabeled files to convert their data\n",
    "        for fs in file_specifier_values:\n",
    "            file_name += f'{fs}{file_specifier_values[fs]}-'\n",
    "        file_name += 'Labeled'\n",
    "\n",
    "        for ed in ending_descriptors:\n",
    "            file_name += '_' + ed\n",
    "\n",
    "        file_name += file_extension\n",
    "            \n",
    "        return file_name\n",
    "\n",
    "\n",
    "\n",
    "    # You will VERY LIKELY have to manually check the last column and fix any mismatches in the rows with 1's \n",
    "        # DO NOT delete the last column if you don't know what it is there for\n",
    "        # (it is to mark which rows the converter skipped since otherwise there might be inconsistencies.\n",
    "        # that way, you can manually change it how you had in mind)\n",
    "    def convert_buffer_num(self, output_folder_path='_', return_df=False, override_output_file_path=False):\n",
    "        if(not self.validate_buffer_num_conversion(self.input_specifiers['BufferNum'], self.output_buffer_num)):\n",
    "            print(f\"Current object/class definitions prohibit the conversion from BufferNum {self.input_specifiers['BufferNum']} to BufferNum {self.output_buffer_num}.\")\n",
    "            return\n",
    "        if (not return_df) and output_folder_path == '_':\n",
    "            output_folder_path = self.input_directory\n",
    "\n",
    "        num_of_inputs = Converter.NUM_OF_INPUTS_PER_TYPE[self.input_specifiers['Type']]\n",
    "\n",
    "        input_dataframe = pd.read_csv(self.input_directory + self.input_file_name, header=None)\n",
    "        input_df_length = input_dataframe.shape[0]\n",
    "        manual_override_required_at = pd.DataFrame(np.zeros((input_df_length,1)), columns = pd.Index([input_dataframe.shape[1]], dtype='int64'))\n",
    "        output_dataframe = input_dataframe.join(manual_override_required_at)\n",
    "\n",
    "        next_class = None\n",
    "        i = 0\n",
    "        while(i < input_df_length):\n",
    "            prev_class = next_class\n",
    "            # This line takes a row and focuses on the labels\n",
    "                # I do want it to crash if the dictionary cannot pull the value at the given index\n",
    "            next_class = input_dataframe[i, np.where(input_dataframe[i, num_of_inputs : input_dataframe.shape[1]]) + num_of_inputs]\n",
    "\n",
    "\n",
    "        if(return_df):\n",
    "            return output_dataframe\n",
    "        # else create spreadsheet\n",
    "        # if you want to override the output_file_path, please do so through the function arguments\n",
    "        if(override_output_file_path):\n",
    "            output_file_path = output_folder_path\n",
    "        else:\n",
    "            output_file_path = output_folder_path + Converter.build_file_name(output_file_specifiers, self.input_beginning_descriptors, self.input_ending_descriptors, self.input_file_extension) # You are too far to the right; go back to the left\n",
    "            # outdated version:\n",
    "            # f\"{output_folder_path}COMBINED_Type{self.output_label_type}-WithClassNum{Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]}-Freq10-Buffer{output_buffer_number}-Labeled_Motion-sessions_23-24_Fall.csv\"\n",
    "\n",
    "        dataframe.to_csv(output_file_path, mode='x')\n",
    "\n",
    "\n",
    "\n",
    "    # output_folder_path should end with a '/'\n",
    "    # if you want to override the output_file_path, please do so through output_folder_path (with override = True)\n",
    "    def convert_label_type(self, output_folder_path='_', return_df=False, override_output_file_path=False):\n",
    "        if(not self.validate_label_type_conversion(self.input_specifiers['Type'], self.output_label_type)):\n",
    "            print(f\"Current object/class definitions prohibit the conversion from Type {self.input_specifiers['Type']} to Type {self.output_label_type}.\")\n",
    "            return\n",
    "        if (not return_df) and output_folder_path == '_':\n",
    "            output_folder_path = self.input_directory\n",
    "\n",
    "        input_dataframe = pd.read_csv(self.input_directory + self.input_file_name, header=None)\n",
    "        #input_input_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.input_label_type]\n",
    "        # input_total_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.input_label_type] + Converter.NUM_OF_CLASSES_PER_TYPE[self.input_label_type]\n",
    "        #output_input_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.output_label_type]\n",
    "        # output_total_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.output_label_type] + Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]\n",
    "        print(input_dataframe.columns)\n",
    "        #row,\n",
    "        print(input_dataframe.iat[1,1])\n",
    "        print(input_dataframe.at[1,2])\n",
    "\n",
    "\n",
    "        # main conversion logic\n",
    "        match (self.input_specifiers['Type'], self.output_label_type):\n",
    "\n",
    "            # We will mainly want to use stuff like df.iloc[[0, 2], [1, 3]] to access rows/columns\n",
    "\n",
    "            case (3, 5):\n",
    "                if(not self.validate_label_type_conversion(3, 5)):\n",
    "                    print(\"Current class definitions prohibit the conversion from Type 3 to Type 5.\")\n",
    "                    return\n",
    "                \n",
    "                input_df_length = input_dataframe.shape[0]\n",
    "                output_dataframe = input_dataframe.iloc[0:input_df_length,0:3]\n",
    "                #df.set_index('key').join(other.set_index('key'))\n",
    "                \n",
    "                # We're mapping (with +3 columns for input):\n",
    "                    # FKS (1) and FTS (3) to FS (1)\n",
    "                    # FKE (2) and FTE (4) to FE (2)\n",
    "                    # LPS (5), LHS (7), RPS (9), and RHS (11) to LS (3)\n",
    "                    # LPE (6), LHE (8), RPE (10), and RHE (12) to LE (4)\n",
    "                    # PS (13) to PS (5)\n",
    "                    # PE (14) to PE (6)\n",
    "                    # S (15) to S (7)\n",
    "                    # O (16) to O (8)\n",
    "\n",
    "                #add 2 to all indexes since 3 input columns\n",
    "                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[3,5]].sum(axis=1))\n",
    "                temp_df.columns = pd.Index([3], dtype='int64')\n",
    "                # print(temp_df.columns)\n",
    "                output_dataframe = output_dataframe.join(temp_df) # (1)\n",
    "\n",
    "                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[4,6]].sum(axis=1))\n",
    "                temp_df.columns = pd.Index([4], dtype='int64')\n",
    "                output_dataframe = output_dataframe.join(temp_df) # (2)\n",
    "\n",
    "                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[7,9,11,13]].sum(axis=1))\n",
    "                temp_df.columns = pd.Index([5], dtype='int64')\n",
    "                output_dataframe = output_dataframe.join(temp_df) # (3)\n",
    "\n",
    "                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[8,10,12,14]].sum(axis=1))\n",
    "                temp_df.columns = pd.Index([6], dtype='int64')\n",
    "                output_dataframe = output_dataframe.join(temp_df) # (4)\n",
    "\n",
    "                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length, 15:19])\n",
    "                temp_df.columns = pd.Index([7,8,9,10], dtype='int64')\n",
    "                output_dataframe = output_dataframe.join(temp_df) # (5:8)\n",
    "\n",
    "                \n",
    "            case _ :\n",
    "                print(f\"Logic not implemented for conversion from Type {self.input_specifiers['Type']} to Type {self.output_label_type}.\")\n",
    "                return\n",
    "        \n",
    "        if return_df:\n",
    "            return output_dataframe\n",
    "        # else create spreadsheet\n",
    "        # if you want to override the output_file_path, please do so through the function arguments\n",
    "        if(override_output_file_path):\n",
    "            output_file_path = output_folder_path\n",
    "        else:\n",
    "            output_file_specifiers = self.input_specifiers\n",
    "            output_file_specifiers['Type'] = self.output_label_type\n",
    "            output_file_specifiers['WithClassNum'] = Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]\n",
    "            print(\"If these are the same, you've modified the input file specifiers (which is not necessarily terrible):\\n\", self.input_specifiers['Type'], output_file_specifiers['Type'])\n",
    "            output_file_path = output_folder_path + Converter.build_file_name(output_file_specifiers, self.input_beginning_descriptors, self.input_ending_descriptors, self.input_file_extension)\n",
    "        # next two comments are old things\n",
    "        # f\"{output_folder_path}COMBINED_Type{self.output_label_type}-WithClassNum{Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]}-Freq10-Labeled_Motion-sessions_23-24_Fall.csv\"\n",
    "        # output_dataframe.drop(np.arange(output_total_columns, input_total_columns), axis=1)\n",
    "        # file names should, starting now, include the number of classes the type has\n",
    "        # \"x, exclusive creation, failing if the file already exists.\" (quote from https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n",
    "        output_dataframe.to_csv(output_file_path, mode='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], dtype='int64')\n",
      "0.334197998\n",
      "-0.948440552\n"
     ]
    }
   ],
   "source": [
    "WORKAREA_PATH = './'\n",
    "INPUT_FILE_PATH = WORKAREA_PATH + 'Data/COMBINED_Type3-Freq10-Labeled_Motion-sessions_23-24_Fall.csv' #'Data/Week 1/Left then Right/Processed/Type3-Freq10-Labeled_Motion-sessions_2023-08-26_17-25-54.csv'\n",
    "OUTPUT_FOLDER_PATH = WORKAREA_PATH + 'Data/'\n",
    "converter = Converter()\n",
    "converter.set_class_conversion_type(3, 5)\n",
    "converter.convert(INPUT_FILE_PATH, OUTPUT_FOLDER_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
