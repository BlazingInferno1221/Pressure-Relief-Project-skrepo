{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loads your CSV file, splits the data into a training set and a test set, and creates a DataLoader for each. The DataLoader can be used to iterate through the data in batches, which is useful for training a neural network.\n",
    "\n",
    "You can replace 'yourfile.csv' with the path to your actual file. Also, note that this assumes your CSV file doesn't have a header. If it does, you might need to skip the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define custom dataset\n",
    "class AccelDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file\n",
    "WORKAREA_PATH = 'C:\\\\Users\\\\fl4m1\\\\Documents\\\\School\\\\CURRENT\\\\2023-24 RCSA Research Assistantship\\\\Work Area\\\\Data'\n",
    "dataframe = pd.read_csv(WORKAREA_PATH + '\\\\Week 1\\\\Left then Right\\\\Processed\\\\Type3-Freq10-Labeled_Motion-sessions_2023-08-26_17-35-54.csv')\n",
    "\n",
    "# Get data and labels from dataframe\n",
    "data = dataframe.iloc[:, :3].values  # x, y, z data\n",
    "labels = dataframe.iloc[:, 3:].values  # labels\n",
    "\n",
    "# Split data into training and test sets\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to tensors\n",
    "data_train = torch.tensor(data_train, dtype=torch.float32)\n",
    "data_test = torch.tensor(data_test, dtype=torch.float32)\n",
    "\n",
    "# Convert labels to tensors\n",
    "labels_train = torch.tensor(labels_train, dtype=torch.long)\n",
    "labels_test = torch.tensor(labels_test, dtype=torch.long)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = AccelDataset(data_train, labels_train)\n",
    "test_dataset = AccelDataset(data_test, labels_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we added 2 more convolutional layers, which can extract more complex features from your accelerometer data. The number of output channels in the convolutional layers gradually increases, as it is common in many deep learning models to gradually increase the complexity and decrease the spatial size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Assuming input sequence length is 100 and each step has 3 dimensions (x, y, z)\n",
    "        self.conv1 = nn.Conv1d(3, 64, kernel_size=5)  # Change the number of input channels to 3\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=5)\n",
    "        #*\n",
    "        #*NOTE FROM STEPHEN:\n",
    "        #*    #why is 256 multiplied with 82? I can see that it is applied after flattening the features, but was 82 chosen based on our old number of output classes?\n",
    "        #*\n",
    "        self.fc1 = nn.Linear(256 * 82, 128) \n",
    "        self.fc2 = nn.Linear(128, 16)   # Output classes are 5 (left, right, forward, pushup, other)\n",
    "        #will be changing the output classes to 10 (left_s, left_e, right_s, right_e, forward_s, forward_e, pushup_s, pushup_e, stationary, other)\n",
    "        #will be changing to type 3 classification: {16 classes: Forward_k_s (1), Forward_k_e (2), Forward_t_s (3), Forward_t_e (4),\n",
    "        #   Left_p_s (5), Left_p_e (6), Left_h_s (7), Left_h_e (8), Right_p_s (9), Right_p_e (10), Right_h_s (11), Right_h_e (12),\n",
    "        #   Pushup_s (13), Pushup_e (14), Stationary (15), Other (16)}\n",
    "        #k stands for knee, t stands for table, p stands for push, h stands for hold, s stands for start, and e stands for end\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('---')\n",
    "        print(x.shape)\n",
    "        print('---')\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        print(x.shape)\n",
    "        print('---')\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)  # Apply softmax to the output layer\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # All dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the dimension of the input to the fully connected layer depends on the output size of your last convolutional layer. This code assumes that after 3 layers of convolution with kernel size 5 and stride 1, the sequence length is reduced to 82 (from the original 100). You may need to adjust this according to your own situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3])\n",
      "---\n",
      "torch.Size([3, 64, 1])\n",
      "---\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 5], expected input[3, 64, 1] to have 3 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fl4m1\\Documents\\School\\CURRENT\\2023-24 RCSA Research Assistantship\\Work Area\\Data Processing and Model Combined.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#inputs = inputs.T\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mreshape(\u001b[39m3\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs) \u001b[39m##error\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\fl4m1\\.conda\\envs\\wsresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\fl4m1\\Documents\\School\\CURRENT\\2023-24 RCSA Research Assistantship\\Work Area\\Data Processing and Model Combined.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fl4m1\\.conda\\envs\\wsresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\fl4m1\\.conda\\envs\\wsresearch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\fl4m1\\.conda\\envs\\wsresearch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 5], expected input[3, 64, 1] to have 3 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": [
    "# Instantiate the network and optimizer\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Assume we have a data loader `dataloader` which loads our accelerometer data\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        print(inputs.shape) # 64 x 3\n",
    "        #inputs = inputs.reshape(1, 64, 3)\n",
    "        #inputs = inputs.T\n",
    "        outputs = net(inputs) ##error\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'Shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fl4m1\\Documents\\School\\CURRENT\\2023-24 RCSA Research Assistantship\\Work Area\\Data Processing and Model Combined.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fl4m1\\.conda\\envs\\wsresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\fl4m1\\Documents\\School\\CURRENT\\2023-24 RCSA Research Assistantship\\Work Area\\Data Processing and Model Combined.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39;49mShape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fl4m1/Documents/School/CURRENT/2023-24%20RCSA%20Research%20Assistantship/Work%20Area/Data%20Processing%20and%20Model%20Combined.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'Shape'"
     ]
    }
   ],
   "source": [
    "# Now we will validate the model using test data\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():   # Since we're not training, we don't need to calculate the gradients\n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
