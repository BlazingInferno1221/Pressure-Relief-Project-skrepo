{"cells":[{"cell_type":"markdown","metadata":{"id":"m4JVkZ51I9pk"},"source":["**Purpose of this file:**\n","\n","This is not necessarily meant to hold full backups of the code; it is meant to hold backups of the occasional pieces of code that were significant and which I do not want to risk losing just yet"]},{"cell_type":"markdown","metadata":{"id":"L6lDVAtHIclI"},"source":["**CLASSES_AND_TAGS_PER_TYPE**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yz1hfT5IgBQ"},"outputs":[],"source":["CLASSES_AND_TAGS_PER_TYPE = {\n","    1: {\n","        # Type 1, Class 1: \"Forward Lean\"\n","        FORWARD_LEAN_CLASS: (\n","            EXERCISE_TAG,\n","            FULL_TAG,\n","            FORWARD_LEAN_TAG,\n","            AMBIGUOUS_STATIONARY_TAG\n","        ),\n","        # Type 1, Class 2: \"Left Lean\"\n","        LEFT_LEAN_CLASS: (\n","            EXERCISE_TAG,\n","            FULL_TAG,\n","            LATERAL_LEAN_TAG,\n","            LEFT_LEAN_TAG,\n","            AMBIGUOUS_STATIONARY_TAG\n","        ),\n","        # Type 1, Class 3: \"Right Lean\"\n","        RIGHT_LEAN_CLASS: (\n","            EXERCISE_TAG,\n","            FULL_TAG,\n","            LATERAL_LEAN_TAG,\n","            RIGHT_LEAN_TAG,\n","            AMBIGUOUS_STATIONARY_TAG\n","        ),\n","        # Type 1, Class 4: \"Pushup\"\n","        PUSHUP_CLASS: (\n","            EXERCISE_TAG,\n","            FULL_TAG,\n","            PUSHUP_TAG,\n","            AMBIGUOUS_STATIONARY_TAG\n","        ),\n","        # Type 1, Class 5: \"Other\"\n","        OTHER_CLASS: (\n","            NONEXERCISE_TAG,\n","            OTHER_TAG,\n","            AMBIGUOUS_STATIONARY_TAG\n","        )\n","    },\n","    2: {\n","        # Type 2, Class 1: \"Forward Lean Start\"\n","        FORWARD_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            FORWARD_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 2, Class 2: \"Forward Lean End\"\n","        FORWARD_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            FORWARD_LEAN_TAG,\n","            NONSTATIONARY_TAG,\n","        ),\n","        # Type 2, Class 3: \"Left Lean Start\"\n","        LEFT_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            LATERAL_LEAN_TAG,\n","            LEFT_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 2, Class 4: \"Left Lean End\"\n","        LEFT_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            LATERAL_LEAN_TAG,\n","            LEFT_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 2, Class 5: \"Right Lean Start\"\n","        RIGHT_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            LATERAL_LEAN_TAG,\n","            RIGHT_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 2, Class 6: \"Right Lean End\"\n","        RIGHT_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            LATERAL_LEAN_TAG,\n","            RIGHT_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 2, Class 7: \"Pushup Start\"\n","        PUSHUP_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            PUSHUP_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 2, Class 8: \"Pushup End\"\n","        PUSHUP_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            PUSHUP_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 2, Class 9: \"Stationary\"\n","        STATIONARY_CLASS: (\n","            AMBIGUOUS_EXERCISE_TAG,\n","            STATIONARY_TAG\n","        ),\n","        # Type 2, Class 10: \"Other\"\n","        OTHER_CLASS: (\n","            NONEXERCISE_TAG,\n","            OTHER_TAG,\n","            NONSTATIONARY_TAG\n","        )\n","    },\n","    3: {\n","        # Type 3, Class 1: \"Forward Knee Lean Start\"\n","        FORWARD_KNEE_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            FORWARD_LEAN_TAG,\n","            FORWARD_KNEE_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 2: \"Forward Knee Lean End\"\n","        FORWARD_KNEE_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            FORWARD_LEAN_TAG,\n","            FORWARD_KNEE_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 3: \"Forward Table Lean Start\"\n","        FORWARD_TABLE_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            FORWARD_LEAN_TAG,\n","            FORWARD_TABLE_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 4: \"Forward Table Lean End\"\n","        FORWARD_TABLE_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            FORWARD_LEAN_TAG,\n","            FORWARD_TABLE_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 5: \"Left Push Lean Start\"\n","        LEFT_PUSH_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            LATERAL_LEAN_TAG,\n","            LEFT_LEAN_TAG,\n","            LATERAL_PUSH_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 6: \"Left Push Lean End\"\n","        LEFT_PUSH_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            LATERAL_LEAN_TAG,\n","            LEFT_LEAN_TAG,\n","            LATERAL_PUSH_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 7: \"Left Hold Lean Start\"\n","        LEFT_HOLD_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            LATERAL_LEAN_TAG,\n","            LEFT_LEAN_TAG,\n","            LATERAL_HOLD_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 8: \"Left Hold Lean End\"\n","        LEFT_HOLD_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            LATERAL_LEAN_TAG,\n","            LEFT_LEAN_TAG,\n","            LATERAL_HOLD_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 9: \"Right Push Lean Start\"\n","        RIGHT_PUSH_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            LATERAL_LEAN_TAG,\n","            RIGHT_LEAN_TAG,\n","            LATERAL_PUSH_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 10: \"Right Push Lean End\"\n","        RIGHT_PUSH_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            LATERAL_LEAN_TAG,\n","            RIGHT_LEAN_TAG,\n","            LATERAL_PUSH_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 11: \"Right Hold Lean Start\"\n","        RIGHT_HOLD_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            LATERAL_LEAN_TAG,\n","            RIGHT_LEAN_TAG,\n","            LATERAL_HOLD_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 12: \"Right Hold Lean End\"\n","        RIGHT_HOLD_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            LATERAL_LEAN_TAG,\n","            RIGHT_LEAN_TAG,\n","            LATERAL_HOLD_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 13: \"Pushup Start\"\n","        PUSHUP_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            PUSHUP_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 14: \"Pushup End\"\n","        PUSHUP_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            PUSHUP_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 3, Class 15: \"Stationary\"\n","        STATIONARY_CLASS: (\n","            AMBIGUOUS_EXERCISE_TAG,\n","            STATIONARY_TAG\n","        ),\n","        # Type 3, Class 16: \"Other\"\n","        OTHER_CLASS: (\n","            NONEXERCISE_TAG,\n","            OTHER_TAG,\n","            NONSTATIONARY_TAG\n","        )\n","    },\n","    4: {\n","        # Type 4, Class 1: \"Forward Lean\"\n","        FORWARD_LEAN_CLASS: (\n","            EXERCISE_TAG,\n","            FULL_TAG,\n","            FORWARD_LEAN_TAG,\n","            AMBIGUOUS_STATIONARY_TAG\n","        ),\n","        # Type 4, Class 2: \"Lateral Lean\"\n","        LATERAL_LEAN_CLASS: (\n","            EXERCISE_TAG,\n","            FULL_TAG,\n","            LATERAL_LEAN_TAG,\n","            AMBIGUOUS_STATIONARY_TAG\n","        ),\n","        # Type 4, Class 3: \"Pushup\"\n","        PUSHUP_CLASS: (\n","            EXERCISE_TAG,\n","            FULL_TAG,\n","            PUSHUP_TAG,\n","            AMBIGUOUS_STATIONARY_TAG\n","        ),\n","        # Type 4, Class 4: \"Other\"\n","        OTHER_CLASS: (\n","            NONEXERCISE_TAG,\n","            OTHER_TAG,\n","            AMBIGUOUS_STATIONARY_TAG\n","        )\n","    },\n","    5: {\n","        # Type 5, Class 1: \"Forward Lean Start\"\n","        FORWARD_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            FORWARD_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 5, Class 2: \"Forward Lean End\"\n","        FORWARD_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            FORWARD_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 5, Class 3: \"Lateral Lean Start\"\n","        LATERAL_LEAN_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            LATERAL_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 5, Class 4: \"Lateral Lean End\"\n","        LATERAL_LEAN_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            LATERAL_LEAN_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 5, Class 5: \"Pushup Start\"\n","        PUSHUP_START_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            START_TAG,\n","            PUSHUP_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 5, Class 6: \"Pushup End\"\n","        PUSHUP_END_CLASS: (\n","            EXERCISE_TAG,\n","            BORDER_TAG,\n","            END_TAG,\n","            PUSHUP_TAG,\n","            NONSTATIONARY_TAG\n","        ),\n","        # Type 5, Class 7: \"Stationary\"\n","        STATIONARY_CLASS: (\n","            AMBIGUOUS_EXERCISE_TAG,\n","            STATIONARY_TAG\n","        ),\n","        # Type 5, Class 8: \"Other\"\n","        OTHER_CLASS: (\n","            NONEXERCISE_TAG,\n","            OTHER_TAG,\n","            NONSTATIONARY_TAG\n","        )\n","    }\n","}\n","\n","\n","\n","\n","i = 0\n","for x, y in zip(SKDescriptors.LIST_OF_CLASSES_AND_TAGS_PER_TYPE_CTS.values(), SKDescriptors.LIST_OF_CLASSES_AND_TAGS_PER_TYPE.values()):\n","    # print(x + \" | \" + y)\n","    print(str(i) + \" Classes: \")\n","    i += 1\n","    for xp, k, yp in zip(x, y.keys(), y.values()):\n","        print(\"\\t\" + str(xp) + \" | \" + k)\n","        # print(type(sorted(list(xp.tagset))))\n","        for xpp, ypp in zip(sorted(list(xp.tagset)), sorted(list(yp))):\n","            print(\"\\t\\t\" + xpp + \" | \" + ypp)\n","            assert xpp == ypp # xpp in yp and ypp in xp\n","        assert str(xp) == k"]},{"cell_type":"markdown","metadata":{"id":"tHr_mYTZNRzQ"},"source":["**Comments Lying Around**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tlByBogBNUvu"},"outputs":[],"source":["\n","    # VALID_TYPE_CONVERSIONS = (\n","    #     (3, 5),\n","    # )\n","    # OVERRIDE_TYPE_VALIDATION = (\n","    #     # This is here only for conversions that\n","    #         # fail validate_class_type_conversion() but not for simple reasons\n","    #         # (simple reasons like accidentally choosing the wrong input/output types\n","    #         # or not listing the correct values in the below dictionaries)\n","    #     # If you add an entry here you may have to change logic of other parts of the code\n","    #         # for instance if the number of columns of the output spreadsheet will be more\n","    #         # than the input spreadsheet, you may have to change the dataframe.drop line at the end\n","    # )\n","\n","\n","\n","\n","\n","    # # Currently these do nothing. If we later change how we want the buffers to function\n","    #     # (not the length of the buffers but which buffers overlap into other classes),\n","    #     # we will be able to do so using this\n","    # VALID_BUFFER_TYPE_CONVERSIONS = ()\n","    # OVERRIDE_BUFFER_TYPE_VALIDATION = (\n","    #     # This is here only for BufferType conversions that\n","    #         # fail validate_buffer_type_conversion() but not for simple reasons\n","    #         # (simple reasons like accidentally choosing the wrong input/output types\n","    #         # or not listing the correct values in the above dictionaries)\n","    #     # If you add an entry here you may have to change logic of other parts of the code\n","    # )\n","\n","\n","    # each buffer type has a dictionary;\n","        # the keys of each dictionary have precedence over the values;\n","        # rules (key-value pairs) listed sooner have priority over later rules\n","    # PRECEDENCE_OF_TAGS_PER_BUFFER_TYPE = {\n","    #     1: {\n","    #         # exercises should have precedence over \"Other\" and \"Stationary\"\n","    #         EXERCISE_TAG: (NONEXERCISE_TAG, AMBIGUOUS_EXERCISE_TAG),\n","    #         # we actually don't want the following line because then in Type 3 and Type 5,\n","    #             # Stationary would have precedence over Other (which would be incorrect)\n","    #         #AMBIGUOUS_EXERCISE_TAG: (NONEXERCISE_TAG,) # the comma here is to make it a tuple #\n","    #         # \"Other\" and \"Moving\" should have precedence over \"Stationary\"\n","    #         NONSTATIONARY_TAG: (STATIONARY_TAG, AMBIGUOUS_STATIONARY_TAG)\n","    #     }\n","    # }"]},{"cell_type":"markdown","metadata":{"id":"5XHvRhxT778m"},"source":["**Hasher... but idk what I'm doing wrong**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpsTwJjz8Bto"},"outputs":[],"source":["\n","    # uig_prev_in = \"\"\n","    # def userIdGenerator(random_str = None):\n","    #     skdsha1 = hashlib.sha1()\n","    #     print(SKDescriptors.uig_prev_in)\n","    #     print(str(str(time.time()).encode(\"utf-8\"))[-4:-1])\n","    #     print(str(time.time())[-3:])\n","    #     # rh_eq_upi = False\n","    #     # if random_hashable == SKDescriptors.uig_prev_in:\n","    #     #     rh_eq_upi = True\n","    #     if random_str == None:\n","    #         # if SKDescriptors.uig_prev_in != None:\n","    #         SKDescriptors.uig_prev_in = str(str(time.time()).encode(\"utf-8\"))[::3] + SKDescriptors.uig_prev_in[::-1]\n","    #     else:\n","    #         SKDescriptors.uig_prev_in = random_str[::-1] + SKDescriptors.uig_prev_in[::-1]\n","    #     if(SKDescriptors.uig_prev_in == \"\"):\n","    #         skdsha1.update(SKDescriptors.uig_prev_in.encode(\"utf-8\"))\n","    #     return skdsha1.hexdigest()[:3]\n","    #     return str(time.time())[-3:]"]},{"cell_type":"markdown","metadata":{},"source":["**Column labels for dataframe... which gets split and converted into numpy arrays immediately after**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","            \n","        # # This combines the input names with the class names\n","        #     # example: ['x', 'y', 'z', 'Forward Lean', 'Left Lean', 'Right Lean', 'Pushup', 'Other']\n","        #     # I use the * operator in conjunction with Python 3.5+'s \"Additional Unpacking Generalizations\"\n","        #         # to unpack two list-likes and combine them into one list\n","        # dataframe.columns = pd.Index([*SKDescriptors.INPUT_NAMES[1], *(str(c) for c in SKDescriptors.CTS_PER_TYPE[classification_type])])"]},{"cell_type":"markdown","metadata":{},"source":["**Test for dynamically altering model outputs into a different label type**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cnnmodel = JFNetModel(10)\n","# cnnmodel.load_model(None, 3)\n","# cnnmodel.load_data(SKFileNameHandler.get_filename_for_classtype(3))\n","\n","# cnnmodel.change_io_specs(5)\n","\n","# # JFSKLoader(SKFileNameHandler.get_filename_for_classtype(5), 10, repress_classes=True)\n","# with torch.no_grad():   # Since we're not training, we don't need to calculate the gradients\n","#     for data in cnnmodel.get_eval_loader().test_dataloader:\n","#         inputs, labels = data\n","#         print(np.shape(SKJFModel.get_outputs(cnnmodel, inputs)))\n","#         break"]},{"cell_type":"markdown","metadata":{},"source":["**get_subclass_mapping() without using get_superclass_mapping()**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["        # SKDescriptors.validate_class_type(input_label_type)\n","        # SKDescriptors.validate_class_type(output_label_type)\n","        # subclasses = {}\n","        # for i, cts in enumerate(SKDescriptors.CTS_PER_TYPE[output_label_type]):\n","        #     subclasses[(i, cts)] = cts.find_subclasses(input_label_type)\n","        #     if not subclasses[(i, cts)]:\n","        #         raise AssertionError(f\"Um, there doesn't appear to be any subclasses for classification type {output_label_type}'s '{cts}' class in classification type {input_label_type}... subclasses found: {subclasses}\")\n","        \n","        # # double checking the result is valid\n","        # for i, cts in enumerate(SKDescriptors.CTS_PER_TYPE[input_label_type]):\n","        #     cts_is_valid_subclass = False\n","        #     for l in subclasses.values():\n","        #         if (i, cts) in l:\n","        #             if cts_is_valid_subclass:\n","        #                 cts_is_valid_subclass = False\n","        #                 break\n","        #             cts_is_valid_subclass = True\n","        #     if not cts_is_valid_subclass:\n","        #         break\n","        # if not cts_is_valid_subclass:\n","        #     print(\"\\nsubclasses per superclass:\")\n","        #     for k, v in subclasses.items():\n","        #         print(f\"\\t({k[0]}, {k[1]}) : [\")\n","        #         for t in v:\n","        #             print(f\"\\t\\t({t[0]}, {t[1]})\")\n","        #         print(\"\\t]\")\n","        #     raise AssertionError(f\"A class from classification type {input_label_type} either does not have a superclass in or has multiple superclasses in classification type {output_label_type}. See above dictionary for details.\")\n","        \n","        # return subclasses"]},{"cell_type":"markdown","metadata":{},"source":["**Old BufferNum and Label Type Conversions**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["    # # You will VERY LIKELY have to manually check the last column and fix any mismatches in the rows with 1's\n","    #     # DO NOT delete the last column if you don't know what it is there for\n","    #     # (it is to mark which rows the converter skipped since otherwise there might be inconsistencies.\n","    #     # that way, you can manually change it how you had in mind)\n","    # def convert_buffer_num(self, output_folder_path='_', return_df=False, override_output_file_path=False):\n","    #     if(not self.validate_buffer_num_conversion(self.input_specifiers['BufferNum'], self.output_buffer_num)):\n","    #         print(f\"Current object/class definitions prohibit the conversion from BufferNum {self.input_specifiers['BufferNum']} to BufferNum {self.output_buffer_num}.\")\n","    #         return\n","    #     if (not return_df) and output_folder_path == '_':\n","    #         output_folder_path = self.input_directory\n","\n","    #     num_of_inputs = Converter.NUM_OF_INPUTS_PER_TYPE[self.input_specifiers['Type']]\n","\n","    #     input_dataframe = pd.read_csv(self.input_directory + self.input_file_name, header=None)\n","    #     input_df_length = input_dataframe.shape[0]\n","    #     manual_override_required_at = pd.DataFrame(np.zeros((input_df_length,1)), columns = pd.Index([input_dataframe.shape[1]], dtype='int64'))\n","    #     output_dataframe = input_dataframe.join(manual_override_required_at)\n","\n","    #     next_class = None\n","    #     i = 0\n","    #     while(i < input_df_length):\n","    #         prev_class = next_class\n","    #         # This line takes a row and focuses on the labels\n","    #             # I do want it to crash if the dictionary cannot pull the value at the given index\n","    #         next_class = input_dataframe[i, np.where(input_dataframe[i, num_of_inputs : input_dataframe.shape[1]]) + num_of_inputs]\n","\n","\n","    #     if(return_df):\n","    #         return output_dataframe\n","    #     # else create spreadsheet\n","    #     # if you want to override the output_file_path, please do so through the function arguments\n","    #     if(override_output_file_path):\n","    #         output_file_path = output_folder_path\n","    #     else:\n","    #         output_file_path = output_folder_path + SKFileNameHandler.build_data_file_name(output_file_specifiers, self.input_beginning_descriptors, self.input_ending_descriptors, self.input_file_extension) # You are too far to the right; go back to the left\n","    #         # outdated version:\n","    #         # f\"{output_folder_path}COMBINED_Type{self.output_label_type}-WithClassNum{Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]}-Freq10-Buffer{output_buffer_number}-Labeled_Motion-sessions_23-24_Fall.csv\"\n","\n","    #     dataframe.to_csv(output_file_path, mode='x')\n","\n","\n","\n","    # # output_folder_path should end with a '/'\n","    # # if you want to override the output_file_path, please do so through output_folder_path (with override = True)\n","    # def convert_label_type(self, output_folder_path='_', return_df=False, override_output_file_path=False):\n","    #     if(not self.validate_label_type_conversion(self.input_specifiers['Type'], self.output_label_type)):\n","    #         print(f\"Current object/class definitions prohibit the conversion from Type {self.input_specifiers['Type']} to Type {self.output_label_type}.\")\n","    #         return\n","    #     if (not return_df) and output_folder_path == '_':\n","    #         output_folder_path = self.input_directory\n","\n","    #     input_dataframe = pd.read_csv(self.input_directory + self.input_file_name, header=None)\n","    #     #input_input_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.input_label_type]\n","    #     # input_total_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.input_label_type] + Converter.NUM_OF_CLASSES_PER_TYPE[self.input_label_type]\n","    #     #output_input_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.output_label_type]\n","    #     # output_total_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.output_label_type] + Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]\n","    #     print(input_dataframe.columns)\n","    #     #row,\n","    #     print(input_dataframe.iat[1,1])\n","    #     print(input_dataframe.at[1,2])\n","\n","\n","    #     # main conversion logic\n","    #     match (self.input_specifiers['Type'], self.output_label_type):\n","\n","    #         # We will mainly want to use stuff like df.iloc[[0, 2], [1, 3]] to access rows/columns\n","\n","    #         case (3, 5):\n","    #             if(not self.validate_label_type_conversion(3, 5)):\n","    #                 print(\"Current class definitions prohibit the conversion from Type 3 to Type 5.\")\n","    #                 return\n","\n","    #             input_df_length = input_dataframe.shape[0]\n","    #             output_dataframe = input_dataframe.iloc[0:input_df_length,0:3]\n","    #             #df.set_index('key').join(other.set_index('key'))\n","\n","    #             # We're mapping (with +3 columns for input):\n","    #                 # FKS (1) and FTS (3) to FS (1)\n","    #                 # FKE (2) and FTE (4) to FE (2)\n","    #                 # LPS (5), LHS (7), RPS (9), and RHS (11) to LS (3)\n","    #                 # LPE (6), LHE (8), RPE (10), and RHE (12) to LE (4)\n","    #                 # PS (13) to PS (5)\n","    #                 # PE (14) to PE (6)\n","    #                 # S (15) to S (7)\n","    #                 # O (16) to O (8)\n","\n","    #             #add 2 to all indexes since 3 input columns\n","    #             temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[3,5]].sum(axis=1))\n","    #             temp_df.columns = pd.Index([3], dtype='int64')\n","    #             # print(temp_df.columns)\n","    #             output_dataframe = output_dataframe.join(temp_df) # (1)\n","\n","    #             temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[4,6]].sum(axis=1))\n","    #             temp_df.columns = pd.Index([4], dtype='int64')\n","    #             output_dataframe = output_dataframe.join(temp_df) # (2)\n","\n","    #             temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[7,9,11,13]].sum(axis=1))\n","    #             temp_df.columns = pd.Index([5], dtype='int64')\n","    #             output_dataframe = output_dataframe.join(temp_df) # (3)\n","\n","    #             temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[8,10,12,14]].sum(axis=1))\n","    #             temp_df.columns = pd.Index([6], dtype='int64')\n","    #             output_dataframe = output_dataframe.join(temp_df) # (4)\n","\n","    #             temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length, 15:19])\n","    #             temp_df.columns = pd.Index([7,8,9,10], dtype='int64')\n","    #             output_dataframe = output_dataframe.join(temp_df) # (5:8)\n","\n","\n","    #         case _ :\n","    #             print(f\"Logic not implemented for conversion from Type {self.input_specifiers['Type']} to Type {self.output_label_type}.\")\n","    #             return\n","\n","    #     if return_df:\n","    #         return output_dataframe\n","    #     # else create spreadsheet\n","    #     # if you want to override the output_file_path, please do so through the function arguments\n","    #     if(override_output_file_path):\n","    #         output_file_path = output_folder_path\n","    #     else:\n","    #         output_file_specifiers = self.input_specifiers\n","    #         output_file_specifiers['Type'] = self.output_label_type\n","    #         output_file_specifiers['WithClassNum'] = Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]\n","    #         print(\"If these are the same, you've modified the input file specifiers (which is not necessarily terrible):\\n\", self.input_specifiers['Type'], output_file_specifiers['Type'])\n","    #         output_file_path = output_folder_path + Converter.build_file_name(output_file_specifiers, self.input_beginning_descriptors, self.input_ending_descriptors, self.input_file_extension)\n","    #     # next two comments are old things\n","    #     # f\"{output_folder_path}COMBINED_Type{self.output_label_type}-WithClassNum{Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]}-Freq10-Labeled_Motion-sessions_23-24_Fall.csv\"\n","    #     # output_dataframe.drop(np.arange(output_total_columns, input_total_columns), axis=1)\n","    #     # file names should, starting now, include the number of classes the type has\n","    #     # \"‘x’, exclusive creation, failing if the file already exists.\" (quote from https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n","    #     output_dataframe.to_csv(output_file_path, mode='x')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNLcoBtO1lSkU67KRyMTXnS","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
