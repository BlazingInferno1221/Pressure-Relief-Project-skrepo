{"cells":[{"cell_type":"code","execution_count":8,"id":"bZLKiFqtPRNs","metadata":{"id":"bZLKiFqtPRNs"},"outputs":[],"source":["# # no need for this since it has nothing outside classes and functions\n","# print(__name__)\n","# if __name__ == \"__main__\" and hasattr(__builtins__,'__IPYTHON__') and ('google.colab' in str(get_ipython())):\n","#     from google.colab import drive\n","#     drive.mount('/content/drive')\n","#     %cd /content/drive/MyDrive/PressureReliefWorkArea/SummerWork/\n","#     !ls"]},{"cell_type":"code","execution_count":9,"id":"b20374ca","metadata":{"id":"b20374ca"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","# import torch.optim as optim\n","import numpy as np\n","from collections.abc import Iterable\n","\n","%run -n HelperFunctions.ipynb\n","# import ipynb\n","# from ipynb.fs.full.HelperFunctions import *"]},{"cell_type":"markdown","id":"5d837446","metadata":{"id":"5d837446"},"source":["This code loads your CSV file, splits the data into a training set and a test set, and creates a DataLoader for each. The DataLoader can be used to iterate through the data in batches, which is useful for training a neural network.\n","\n","You can replace 'yourfile.csv' with the path to your actual file. Also, note that this assumes your CSV file doesn't have a header. If it does, you might need to skip the first row."]},{"cell_type":"code","execution_count":10,"id":"b7bd7f69","metadata":{"id":"b7bd7f69"},"outputs":[],"source":["class JFSKAccelDataset(Dataset):\n","    def __init__(self, data, labels, sequence_length=None):\n","        # if(labels == None):\n","        #     self.data = data.data\n","        #     self.labels = data.labels\n","        #     self.sequence_length = data.sequence_length\n","        #     return\n","        self.data = data\n","        self.labels = labels\n","        self.sequence_length = sequence_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx].transpose(0, 1), self.labels[idx]  # Transposing the sequence and channel dimensions\n","        \n","        \n","    def group(self):\n","        self.data = [self.data[i:i+self.sequence_length] for i in range(len(self.data) - self.sequence_length + 1)]\n","        self.labels = self.labels[(int)(self.sequence_length/2) - 1 : len(self.labels) - (self.sequence_length - (int)(self.sequence_length/2))]\n","        # change to get the majority"]},{"cell_type":"code","execution_count":11,"id":"OBcQ2UO1K1tM","metadata":{"id":"OBcQ2UO1K1tM"},"outputs":[],"source":["class SKInputConverter:\n","    def __init__(self, dataframe, classtype, bufferpref = \"Inner\"):\n","        self.dataframe = dataframe\n","        SKDescriptors.validate_class_type(classtype)\n","        self.classtype = classtype\n","        self.bufferpref = bufferpref\n","        self.inputnum = SKDescriptors.NUM_OF_INPUTS_PER_TYPE[classtype]\n","\n","    def result(self):\n","        return self.dataframe, self.inputnum\n","\n","    def diff(self):\n","        pass\n","        return self\n","\n","    def remove_outliers(self, rem_type = None, rem_func = None, *args, **kwargs):\n","        pass\n","        return self\n","\n","    def normalize(self, norm_type = None, norm_func = None, *args, **kwargs):\n","        pass\n","        return self\n","\n","    def combine(self, comb_type = None, comb_func = None, *args, **kwargs):\n","        if comb_type != None or comb_func != None or args or kwargs:\n","            raise NotImplementedError(f\"SKInputConverter.combine() has no implemented parameters\")\n","        self.dataframe = self.dataframe.iloc[:,:self.inputnum].apply(np.linalg.norm).join(self.dataframe.iloc[:,self.inputnum:])\n","        self.dataframe.columns = pd.Index(np.arange(len(self.dataframe.columns) - self.inputnum + 1))\n","        self.inputnum = 1\n","        return self"]},{"cell_type":"code","execution_count":12,"id":"cc4ed681","metadata":{"id":"cc4ed681"},"outputs":[],"source":["class JFSKLoader:\n","    def __init__(self, file_path, sequence_length = None, repress_classes = True, *args, **kwargs):\n","\n","\n","        # 1. open file\n","\n","        # Gather file info\n","        # self.file_directory, self.beginning_descriptors, self.file_name, self.ending_descriptors, self.file_extension, self.specifier_values = SKFileNameHandler.read_data_file_name(file_path)\n","        self.file_directory, _, _, _, file_extension, self.specifier_values = SKFileNameHandler.read_data_file_name(file_path)\n","        classification_type = self.specifier_values[SKDescriptors.CLASSIFICATION_TYPE_FS]\n","        input_num = SKDescriptors.NUM_OF_INPUTS_PER_TYPE[classification_type]\n","\n","        match file_extension:\n","            case \".csv\":\n","                dataframe = pd.read_csv(file_path)\n","                # code test file: Data/Week 1/Left then Right/Processed/Type3-Freq10-Labeled_Motion-sessions_2023-08-26_17-25-54.csv\n","                # classifier training file: Data/COMBINED_Type3-Freq10-Labeled_Motion-sessions_23-24_Fall.csv\n","            case _:\n","                raise NotImplementedError(f\"JFSKLoader is not equipped to open {file_extension} files.\")\n","\n","\n","        # 2. split dataset into data and labels\n","\n","        # Get data and labels from dataframe\n","        data = dataframe.iloc[:, :input_num].to_numpy()  # x, y, z data\n","        labels = dataframe.iloc[:, input_num:].to_numpy()  # labels\n","\n","\n","        # 3. make adjustments related to the data\n","        # THIS is where we would use SKInputConverter\n","\n","\n","        # 4. group\n","        self.sequence_length = sequence_length\n","        self.g_dataset = JFSKAccelDataset(data, labels, sequence_length)\n","        if sequence_length is not None:\n","            self.g_dataset.group()\n","\n","\n","        # 5. make adjustments related to the labels\n","        if repress_classes:\n","        # if args and args[0]:\n","        #     if len(args) > 1:\n","        #         self.repress_classes(*(args[1:]), **kwargs)\n","        #     else:\n","        #         self.repress_classes(**kwargs)\n","        # elif kwargs.pop(\"repress_classes\", False):\n","            self.repress_classes(*args, **kwargs)\n","\n","\n","        # 6. randomize\n","        data_train, data_test, labels_train, labels_test = train_test_split(self.g_dataset.data, self.g_dataset.labels, test_size=0.2, random_state=42)\n","\n","\n","        # 7. create dataloader\n","\n","\n","        # Convert data to tensors\n","        data_train = torch.tensor(np.array(data_train), dtype=torch.float32)  \n","        data_test = torch.tensor(np.array(data_test), dtype=torch.float32)\n","\n","        # Convert labels to tensors and get max index (assuming one-hot encoding)\n","        labels_train = torch.argmax(torch.tensor(np.array(labels_train), dtype=torch.float32), dim=1)\n","        labels_test = torch.argmax(torch.tensor(np.array(labels_test), dtype=torch.float32), dim=1)\n","\n","        # Create data loaders\n","        train_dataset = JFSKAccelDataset(data_train, labels_train, self.sequence_length)\n","        test_dataset = JFSKAccelDataset(data_test, labels_test, self.sequence_length)\n","\n","        self.train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","        self.test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","\n","\n","\n","    # target_classes = [\"Other\", \"Stationary\"], rep_format = 'str', rep_func = np.mean, skip_repressed = True, apply_to_all = False, *args, **kwargs\n","    def repress_classes(self, target_classes = None, rep_format = 'str', rep_func = np.mean, skip_repressed = True, apply_to_all = False, *args, **kwargs):\n","        classification_type = self.specifier_values[SKDescriptors.CLASSIFICATION_TYPE_FS]\n","        \n","        # NOTE: the logic here only works for one-hot vectors\n","        if not SKDescriptors.NUM_OF_OUTPUTS_PER_TYPE[classification_type] == 1:\n","            raise NotImplementedError(f\"JFSKLoader.repress_classes() with repress_stationary=True may not be equipped to fairly sample stationary data for classification types with outputs that are not one-hot vectors.\")\n","\n","        if not callable(rep_func):\n","            raise NotImplementedError(f\"JFSKLoader.repress_classes()'s rep_func must currently be a function\\\n","                                      \\n\\tIf you want more complex logic where you'd test for a string or something, feel free to alter the code\")\n","\n","        if target_classes is None:\n","            target_classes = [SKDescriptors.OTHER_TAG, SKDescriptors.STATIONARY_TAG]\n","            rep_format = 'tag'\n","\n","        \n","\n","        temp_list = []\n","        match rep_format:\n","            case 'str' | 'cts':\n","                for i, cts in enumerate(SKDescriptors.CTS_PER_TYPE[classification_type]):\n","                    if cts in target_classes:\n","                        temp_list.append(i)\n","\n","                if len(temp_list) != len(target_classes):\n","                    print(f\"\\nWARNING: The following target_classes were not kept as they do not correspond to classification_type '{classification_type}':\\n\")\n","                    for cts in target_classes:\n","                        if not any(cts == SKDescriptors.CTS_PER_TYPE[classification_type][i] for i in temp_list):\n","                            print(f\"\\t{cts}\\n\")\n","\n","            case 'tag':\n","                for i, cts in enumerate(SKDescriptors.CTS_PER_TYPE[classification_type]):\n","                    for tag in target_classes:\n","                        if tag in cts:\n","                            temp_list.append(i)\n","\n","            case 'num' | 'int':\n","                forwarn_active = False\n","                for i in target_classes:\n","                    if i in np.arange(SKDescriptors.NUM_OF_CLASSES_PER_TYPE[classification_type]):\n","                        temp_list.append(i)\n","                        continue\n","\n","                    if not forwarn_active:\n","                        print(f\"\\nWARNING: The following target_classes were not kept as they do not correspond to classification_type '{classification_type}':\\n\")\n","                        forwarn_active = True\n","                    print(f\"\\t{i}\\n\")\n","                \n","            case _ :\n","                raise AssertionError(\"You can only pass 'str', 'tag', 'cts', 'num', or 'int' into the rep_format parameter of JFSKLoader.repress_classes()\\\n","                                     \\n\\t\\t'str' is used when you want to pass the class names (as strings) of classes it should repress\\\n","                                     \\n\\t\\t'tag' is used when you want to pass the class tags (as strings) it should repress\\\n","                                     \\n\\t\\t'cts' is used when you want to pass the classes (as ClassTagSets) it should repress\\\n","                                     \\n\\t\\t'int' and 'num' are used when you want to pass the indices of the classes it should repress\")\n","            \n","        target_classes = temp_list\n","\n","        \n","\n","        if skip_repressed:\n","            accounted = np.delete(self.g_dataset.labels, target_classes, axis=1)\n","        else:\n","            accounted = self.g_dataset.labels\n","\n","        if apply_to_all:\n","            adjusted = np.arange(SKDescriptors.NUM_OF_CLASSES_PER_TYPE[classification_type])\n","        else:\n","            adjusted = target_classes\n","\n","        count_ones = lambda x: dict(zip(*np.unique(x, return_counts = True))).get(1, 0)\n","        class_counts = np.apply_along_axis(count_ones, 0, accounted)\n","        adjustment_height = int(rep_func(class_counts, *args, **kwargs))\n","        print(adjustment_height)\n","\n","        for i in adjusted:\n","            # class_i_rows_indexed = np.nonzero(self.g_dataset.labels[i][:])\n","            class_i_rows_indexed = np.nonzero(np.transpose(self.g_dataset.labels)[i][:])\n","            del_rows_not_indexed = np.random.randint(len(class_i_rows_indexed), size = max(0, len(class_i_rows_indexed) - adjustment_height))\n","            print(len(class_i_rows_indexed))\n","            print(np.ndarray(del_rows_not_indexed))\n","            if del_rows_not_indexed:\n","                del_rows_indexed = class_i_rows_indexed[del_rows_not_indexed]\n","            else:\n","                del_rows_indexed = del_rows_not_indexed\n","            print(i)\n","            print(np.shape(self.g_dataset.labels))\n","            self.g_dataset.data = np.delete(self.g_dataset.data, del_rows_indexed, axis = 0)\n","            self.g_dataset.labels = np.delete(self.g_dataset.labels, del_rows_indexed, axis = 0)\n","            print(np.shape(self.g_dataset.labels))\n","\n","\n","    def count_instances(series):\n","        return dict(zip(*np.unique(series, return_counts = True))).get(1, 0)\n","\n","        # ci_arr = np.unique(series, return_counts = True)\n","        # return dict(zip(ci_arr[0], ci_arr[1])).get(1, 0)\n"]},{"cell_type":"code","execution_count":13,"id":"e303230b","metadata":{},"outputs":[],"source":["class SKLabelConverter:\n","\n","    VALID_TYPE_CONVERSIONS = (\n","        (3, 5),\n","    )\n","    OVERRIDE_TYPE_VALIDATION = (\n","        # This is here only for conversions that\n","            # fail validate_class_type_conversion() but not for simple reasons\n","            # (simple reasons like accidentally choosing the wrong input/output types\n","            # or not listing the correct values in the below dictionaries)\n","        # If you add an entry here you may have to change logic of other parts of the code\n","            # for instance if the number of columns of the output spreadsheet will be more\n","            # than the input spreadsheet, you may have to change the dataframe.drop line at the end\n","    )\n","\n","\n","\n","    # Currently these do nothing. If we later change how we want the buffers to function\n","        # (not the length of the buffers but which buffers overlap into other classes),\n","        # we will be able to do so using this\n","    VALID_BUFFER_TYPE_CONVERSIONS = ()\n","    OVERRIDE_BUFFER_TYPE_VALIDATION = (\n","        # This is here only for BufferType conversions that\n","            # fail validate_buffer_type_conversion() but not for simple reasons\n","            # (simple reasons like accidentally choosing the wrong input/output types\n","            # or not listing the correct values in the above dictionaries)\n","        # If you add an entry here you may have to change logic of other parts of the code\n","    )\n","\n","\n","\n","    def __init__(self, labeled_data_file = None, *args):\n","        # if not all(n == Converter.NUM_OF_LABEL_TYPES for n in (len(Converter.NUM_OF_INPUTS_PER_TYPE), len(Converter.NUM_OF_CLASSES_PER_TYPE), len(Converter.NUM_OF_OUTPUTS_PER_TYPE))):\n","        #     print(\"Converter is not usable if defining dictionaries do not match corresponding dictionaries in size.\")\n","        #     print(\"Fix and rerun the code to use the converter\")\n","        #     return\n","        if labeled_data_file is not None:\n","            self.input_directory, self.input_beginning_descriptors, self.input_file_name, self.input_ending_descriptors, self.input_file_extension, self.input_specifiers = SKFileNameHandler.read_data_file_name(labeled_data_file)\n","            self.output_label_type = -1\n","            self.output_freq = -1\n","            self.output_buffer_type = -1\n","            self.output_buffer_num = -1\n","        else:\n","            self.input_specifiers = args[0]\n","\n","        self.type_validated = False\n","        self.buffer_num_validated = False\n","\n","\n","\n","    def validate_label_type_conversion(self, input_label_type, output_label_type):\n","        # validating type values' consistency\n","        has_valid_types = SKDescriptors.validate_class_type(input_label_type) and SKDescriptors.validate_class_type(output_label_type)\n","        # input_label_type matches self.input_label_type\n","        matches_input_file = self.input_specifiers.get(SKDescriptors.CLASSIFICATION_TYPE_FS, -1) == input_label_type\n","        # input_label_type corresponds to WithClassNum value stored in self\n","        consistent_with_class_num = self.input_specifiers.get(SKDescriptors.WITH_CLASS_NUMBER_FS, -1) == SKDescriptors.NUM_OF_CLASSES_PER_TYPE[input_label_type]\n","        # has valid values (compared to type dictionaries and the conversion file)\n","        has_consistent_values = has_valid_types and matches_input_file and consistent_with_class_num\n","\n","        # validating conversion logic\n","        # is a type conversion for which someone implemented the logic\n","        is_listed = (input_label_type, output_label_type) in SKLabelConverter.VALID_TYPE_CONVERSIONS #.get((input_label_type, output_label_type), False)\n","        # is a logical input type conversion\n","        is_not_to_more_inputs = SKDescriptors.NUM_OF_INPUTS_PER_TYPE.get(input_label_type, 0) >= SKDescriptors.NUM_OF_INPUTS_PER_TYPE.get(output_label_type, 1)\n","        # is a logical output type conversion when only one class chosen at a time\n","        is_to_fewer_classes = SKDescriptors.NUM_OF_CLASSES_PER_TYPE.get(input_label_type, 0) > SKDescriptors.NUM_OF_CLASSES_PER_TYPE.get(output_label_type, 0)\n","        # may be logical output type conversion if we are converting from\n","            # an output with a \"multi-hot\" vector to an input with a one-hot vector\n","        input_is_not_one_hot_type = SKDescriptors.NUM_OF_OUTPUTS_PER_TYPE.get(input_label_type, 1) != 1\n","        # all conversion logic between types is sound\n","        has_valid_logic = is_listed and is_not_to_more_inputs and (is_to_fewer_classes or input_is_not_one_hot_type)\n","\n","        # allowing override\n","        # the others are to keep someone from accidentally making a \"bad conversion,\"\n","            # but this one is to allow more-complex conversions that are possible,\n","            # given that someone manually listed the conversion in OVERRIDE_TYPE_VALIDATION\n","        # this does not override the conversion if the file is incorrect or if the types are invalid\n","        is_overridden = (input_label_type, output_label_type) in SKLabelConverter.OVERRIDE_TYPE_VALIDATION #.get((input_label_type, output_label_type), False)\n","\n","        return has_consistent_values and (has_valid_logic or is_overridden)\n","\n","\n","    def validate_buffer_num_conversion(self, input_buffer_num, output_buffer_num):\n","        # validate consistency\n","        # both buffer nums are non-negative\n","        has_nonnegative_buffer_nums = input_buffer_num >= 0 and output_buffer_num >= 0\n","        # input_buffer_num matches self.input_buffer_num\n","        matches_input_file = self.input_specifiers.get(SKDescriptors.BUFFER_NUMBER_FS, -1) == input_buffer_num\n","        # BufferType is valid\n","        has_valid_buffer_type = self.input_specifiers.get(SKDescriptors.BUFFER_TYPE_FS, 0) in np.arange(1, SKDescriptors.NUM_OF_BUFFER_TYPES + 1)\n","        # combining\n","        has_consistent_values = has_nonnegative_buffer_nums and matches_input_file and has_valid_buffer_type\n","        # returning\n","        return has_consistent_values\n","\n","\n","    def set_label_type_conversion(self, input_label_type, output_label_type):\n","        #NOTE that types have not yet been implemented as tuple labels\n","        if(not self.validate_label_type_conversion(input_label_type, output_label_type)):\n","            print(f\"Current object/class definitions prohibit the conversion from Type {input_label_type} to Type {output_label_type}.\")\n","            self.type_validated = False\n","            return\n","        #self.input_label_type = input_label_type\n","        self.output_label_type = output_label_type\n","        self.type_validated = True\n","\n","\n","    def set_buffer_num_conversion(self, input_buffer_num, output_buffer_num):\n","        if(not self.validate_buffer_num_conversion(input_buffer_num, output_buffer_num)):\n","            print(f\"Current object/class definitions prohibit the conversion from BufferNum {input_buffer_num} to BufferNum {output_buffer_num}.\")\n","            self.buffer_num_validated = False\n","            return\n","        #self.input_buffer_num = input_buffer_num\n","        self.output_buffer_num = output_buffer_num\n","        self.buffer_num_validated = True\n","\n","\n","\n","\n","    def convert_label_type(self, input_dataframe, is_df = True, to_file = False, labels_only = True, df_datatype = torch.Tensor, feedback = False):\n","        if not self.type_validated:\n","            raise AssertionError(\"Yeah, no. You need to set the label type successfully before trying any conversions\")\n","\n","        input_label_type = self.input_specifiers.get(SKDescriptors.CLASSIFICATION_TYPE_FS, -1)\n","\n","\n","        base_constr = lambda dataframe_like = None, size = 0: df_datatype(dataframe_like) if dataframe_like is not None else df_datatype(np.empty((size, 0)))\n","        select_cols = lambda dataframe, indices: dataframe[:, indices] if not(isinstance(indices, Iterable) and len(indices) > 1) or isinstance(indices, str) else base_constr(np.concatenate([dataframe[:, i] for i in indices], axis = 0))\n","        merge_cols = lambda cols: base_constr(np.sum(cols, axis = 1))\n","        append_col = lambda dataframe, col: base_constr(np.concatenate((dataframe, col), axis = 1))\n","\n","        match df_datatype:\n","            case torch.Tensor:\n","                # copy = lambda dataframe_like: dataframe_like.clone().detach().requires_grad_(dataframe_like.requires_grad)\n","                base_constr = lambda dataframe_like = None, size = 0: torch.from_numpy(dataframe_like) if dataframe_like is not None else torch.empty((size, 0), dtype=input_dataframe.dtype, layout=input_dataframe.layout, requires_grad=input_dataframe.requires_grad)\n","                select_cols = lambda dataframe, indices: dataframe[:, indices].unsqueeze(1) if not(isinstance(indices, Iterable) and len(indices) > 1) or isinstance(indices, str) else torch.cat([dataframe[:, i].unsqueeze(1) for i in indices], dim = 1)\n","                merge_cols = lambda cols: torch.sum(cols, dim = 1).unsqueeze(1)\n","                append_col = lambda dataframe, col: torch.cat((dataframe, col), dim = 1)\n","            case _ :\n","                raise NotImplementedError(f\"SKLabelConverter.convert_label_type is not yet equipped to handle '{(str)(df_datatype)}'.\\\n","                                          \\n\\t\\t\\tTry using 'torch.Tensor' or implement logic for a different type\")\n","\n","\n","        if not is_df:\n","            superclasses = SKDescriptors.get_superclass_dict(input_label_type, self.output_label_type)\n","            output_dataframe = base_constr(np.vectorize(superclasses.__getitem__)(input_dataframe))\n","\n","            # a, b = np.unique(np.array())\n","            # output_dataframe = \n","\n","            # output_dataframe = np.ndarray(input_dataframe.shape)\n","\n","            # output_dataframe = input_dataframe\n","            # for i in range(len(input_dataframe)):\n","            #     print(len(input_dataframe))\n","            #     print(i)\n","            #     print(input_dataframe)\n","            #     print(input_dataframe[i])\n","            #     print(\"yippee\")\n","            #     output_dataframe[i] = superclasses[input_dataframe[i]]\n","            if feedback:\n","                print(f\"Label conversion from type {input_label_type} to type {self.output_label_type} by changing output column num\")\n","            return output_dataframe\n","        \n","\n","        subclasses = SKDescriptors.get_subclass_dict(input_label_type, self.output_label_type)\n","        input_num = SKDescriptors.NUM_OF_INPUTS_PER_TYPE[input_label_type]\n","        if labels_only:\n","            output_dataframe = base_constr(size = np.shape(input_dataframe)[0])\n","        else:\n","            output_dataframe = select_cols(input_dataframe, slice(input_num))\n","            input_dataframe = select_cols(input_dataframe, slice(input_num, input_num + SKDescriptors.NUM_OF_OUTPUTS_PER_TYPE[input_label_type]))\n","        # this is what converts the data\n","        # if you want custom conversion logic, you might want to start reworking earlier parts of the function\n","            # and leave this here since this is highly abstract and allows for most needed conversions\n","        if feedback:\n","            print(f\"Label conversion from type {input_label_type} to type {self.output_label_type}:\")\n","        for (i, cts), l in subclasses.items():\n","            col_inds = [t[0] for t in l]\n","            if not col_inds:\n","                raise AssertionError(\"Not only did we not find any superclasses, but we failed to detect such with our first assertion test. You will probably need to do some serious searching for this bug.\")\n","            if feedback:\n","                print(f\"\\tNew class {i} replaces old classes {col_inds}\")\n","            old_cols = select_cols(input_dataframe, col_inds)\n","            if len(col_inds) > 1:\n","                new_col = merge_cols(old_cols)\n","            output_dataframe = append_col(output_dataframe, new_col)\n","\n","\n","        if to_file:\n","            raise NotImplementedError(\"Saving altered data labels to a file does not work currently. Reimplementation of this will hopefully be easy, but it is not a priority at the moment of writing this\")\n","        else:\n","            return output_dataframe"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":5}
