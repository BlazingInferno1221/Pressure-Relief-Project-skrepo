{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1444,"status":"ok","timestamp":1716533466997,"user":{"displayName":"Stephen Ketola","userId":"11844316096403388973"},"user_tz":300},"id":"A9MioRZAluGY","outputId":"5c1c0014-8e49-4457-dcc8-23cbabf1a47d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/PressureReliefWorkArea/SummerWork\n","AbstractModel.ipynb  DataProcessing.ipynb   RunAndEvaluation.ipynb\n","CNNModel.ipynb\t     HelperFunctions.ipynb\n"]}],"source":["# # no need for this since it has nothing outside classes and functions\n","# print(__name__)\n","# if __name__ == \"__main__\" and hasattr(__builtins__,'__IPYTHON__') and ('google.colab' in str(get_ipython())):\n","#     from google.colab import drive\n","#     drive.mount('/content/drive')\n","#     %cd /content/drive/MyDrive/PressureReliefWorkArea/SummerWork/\n","#     !ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnGqE8gRlnfl"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from abc import ABC, abstractmethod\n","\n","\n","\n","# -n does not work apparently??\n","    # __name__ == \"__main__\" even with -n.\n","# I commented under an issue logged on IPython's GitHub repository requesting this fix,\n","    # and I will be reposting the issue if it is not seen\n","    # (since that issue is very old and appears to have been left unseen so far)\n","%run -n DataProcessing.ipynb\n","# but apparently the ipynb module hates running %cd and !ls AND %run in an imported notebook???\n","    # I can't even import a second ipynb file from inside the first import...\n","# !pip install ipynb\n","# import ipynb\n","# from ipynb.fs.full.DataProcessing import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"clacUmuVlnfp"},"outputs":[],"source":["class SKJFModel(ABC):\n","\n","    def tempfunc_use_unadjusted(self):\n","        cur_size = 2 # len(self.__loader.handler)\n","        hacky_tuple = (3, 2, 5, 6, 7, 8)\n","        dl_ind_list = list(self.__loader.current_dataloaders)\n","        dl_ind_list[0] = hacky_tuple.index(self.train_class_type) * cur_size\n","        print(f\"Changed active dataloaders from indices {self.__loader.current_dataloaders} to indices {tuple(dl_ind_list)}\")\n","        self.__loader.current_dataloaders = tuple(dl_ind_list)\n","\n","\n","    def tempfunc_prepare_loader(self):\n","        cur_size = 2\n","        hacky_tuple = (2, 5, 6, 7, 8)\n","        # dl_ind_list = list(self.__loader.current_dataloaders)\n","        for classification in hacky_tuple:\n","            self.__label_converter.set_label_type_conversion(3, classification)\n","            for i in range(cur_size):\n","                self.__loader.handler.recall_state(i, False)\n","                desc = list(self.__loader.handler.description)\n","                desc[5] = str(classification)\n","                self.__loader.handler.apply(lambda ds: SKDatasetHandler.save_data_and_labels([ds, ds.data, self.__label_converter.convert_label_type(ds.labels)]))\n","                self.__loader.handler.description = \"\".join(desc)\n","                # f\"Type {classification}, Unchanged\" # StatAndOth Repressed\"\n","                self.__loader.handler.classification = classification\n","                self.__loader.handler.log_state(False)\n","\n","    # this currently only truly works with my current setup in RunAndEvaluation.ipynb\n","        # if you alter enough that you can remove this, don't forget to alter change_io_type() as well\n","    def tempfunc_mount_loader(self, loader, train_classification, test_classification = None):\n","        self.__loader = loader\n","        self.train_class_type = train_classification\n","        self.__eval_class_type = test_classification\n","\n","        # be weary,\n","        # I forget what I was going to say next, but you get the picture\n","        hacky = True\n","        if hacky:\n","            # no the stuff in this if block is not the only hacky stuff in this function\n","                # but it helps bring attention to it so it doesn't get forgotten\n","            print(\"WARNING: hacky code being used which is not as abstract/generalized as other functions\")\n","        cur_size = 2 # len(self.__loader.handler)\n","        hacky_tuple = (3, 2, 5, 6, 7, 8)\n","        dl_ind_list = list(self.__loader.current_dataloaders)\n","        # don't do what the below comment says, it is more hacky than the current. Consider making stuff less hacky tho\n","        # add this back in later, and comment out the loop below it (at least for more general situations)\n","        # if only_type3:\n","        #     for i in indices:\n","        #         dl_ind_list[i] += cur_size\n","        # else:\n","        #     for i in indices:\n","        #         dl_ind_list[i] = cur_size * 2 - 1\n","        if not hacky:\n","            _, indices = self.__loader.get_dataloaders(None, \"Train\", True)\n","            # this is still hacky... I had to hack my own hack\n","            for i in indices:\n","                dl_ind_list[i] = (dl_ind_list[i] % 2) + len(self.__loader.handler) - cur_size\n","        dl_ind_list[0] = hacky_tuple.index(train_classification) * 2 + 1\n","        dl_ind_list[1] = hacky_tuple.index(train_classification) * 2\n","        print(f\"Changed active dataloaders from indices {self.__loader.current_dataloaders} to indices {tuple(dl_ind_list)}\")\n","        self.__loader.current_dataloaders = tuple(dl_ind_list)\n","\n","    def __init__(self, sequence_length = None):\n","        super(SKJFModel, self).__init__()\n","        # self.loader = JFLoader(file_path, sequence_length)\n","        self.sequence_length = sequence_length\n","        self.train_class_type = None\n","        # self.train_loader = None\n","        self.__eval_class_type = None\n","        # self.__eval_loader = None\n","        self.__label_converter = None\n","        # self.__counter = 0\n","\n","        self.__loader = None\n","        self.input_FS = None\n","        self.output_FS = None\n","        self.temp_tracker = 0\n","\n","    # def get_eval_loader(self):\n","    #     if self.__eval_loader is None:\n","    #         return self.train_loader\n","    #     return self.__eval_loader\n","\n","    def get_eval_class_type(self):\n","        if self.__eval_class_type is None:\n","            return self.train_class_type\n","        return self.__eval_class_type\n","    \n","    def get_loader(self):\n","        return self.__loader\n","    \n","    def get_outputs(self, inputs, feedback = False):\n","        # if self.__counter >= 5:\n","        #     raise RecursionError(\"SKJFModel.get_outputs() has detected what may be an infinite loop\")\n","        \n","        if feedback:\n","            print(\"inputs:\")\n","            print(inputs)\n","\n","        # self.__counter += 1\n","        outputs = type(self).get_outputs(self, inputs, False)\n","        # self.__counter -= 1\n","\n","        # if self.train_class_type == 3 and self.__eval_class_type == 5:\n","        #     # print(np.shape(outputs))\n","        #     outputs = self.__label_converter.convert_label_type(outputs, False, False, True, torch.Tensor, feedback)\n","        #     # print(np.shape(outputs))\n","\n","        if feedback:\n","            print(\"outputs:\")\n","            print(outputs)\n","\n","        return outputs\n","        # raise NotImplementedError(f\"SKJFModel.__get_outputs() is an abstract method and should be defined before used.\")\n","\n","\n","\n","\n","    @abstractmethod\n","    def load_model(self, file_path, class_type):\n","        ...\n","        # raise NotImplementedError(f\"SKJFModel.load_model() is an abstract method and should be defined before used.\")\n","\n","    @abstractmethod\n","    def train(self, feedback = False):\n","        ...\n","        # raise NotImplementedError(f\"SKJFModel.train() is an abstract method and should be defined before used.\")\n","\n","\n","\n","\n","    def change_io_specs(self, classification, *args, **kwargs):\n","        # if(class_type != 5 or self.train_class_type != 3):\n","        #     raise NotImplementedError(\"Yeah, this function was cobbled together. I strongly suggest putting other loading logic into place in places besides here before trying to work on it\")\n","        # validate_conversion(self.train_class_type, class_type)\n","\n","        # if args:\n","        #     repress_classes = args[0]\n","        #     if len(args) > 1:\n","        #         args = args[1:]\n","        #     else:\n","        #         args = []\n","        # else:\n","        #     repress_classes = kwargs.pop(\"repress_classes\", True)\n","\n","        # self.__eval_class_type = class_type\n","        # self.__eval_loader = JFSKLoader(SKFileNameHandler.get_filename_for_classtype(class_type), self.sequence_length, repress_classes, *args, **kwargs)\n","        self.__eval_class_type = classification\n","        # self.__loader = JFSKLoader(SKFileNameHandler.get_filename_for_classtype(class_type), self.sequence_length, repress_classes, *args, **kwargs)\n","        if self.__label_converter is None:\n","            self.__label_converter = SKLabelConverter(None, self.__loader.specifier_values)\n","        self.__label_converter.input_specifiers[SKDescriptors.CLASSIFICATION_TYPE_FS] = self.train_class_type\n","        self.__label_converter.input_specifiers[SKDescriptors.WITH_CLASS_NUMBER_FS] = 0\n","        self.__label_converter.set_label_type_conversion(self.train_class_type, classification)\n","\n","        # right now this uses Type 3 dataset changes as the backbone. I feel like doing this\n","            # any other way would be more work than it's currently worth (at the time of typing this),\n","            # but feel free to take a crack at it\n","        only_type3 = True\n","        hacky = True\n","        if hacky:\n","            # no the stuff in this if block is not the only hacky stuff in this function\n","                # but it helps bring attention to it so it doesn't get forgotten\n","            print(\"WARNING: hacky code being used which is not as abstract/generalized as other functions\")\n","        cur_size = 2 # len(self.__loader.handler)\n","        hacky_tuple = (3, 2, 5, 6, 7, 8)\n","        # dl_ind_list = list(self.__loader.current_dataloaders)\n","        # for i in range(cur_size):\n","        #     if self.__loader.handler.description.find('Type 3') == 0:\n","        #         desc = list(self.__loader.handler.description)\n","        #         desc[5] = str(classification)\n","        #         self.__loader.handler.recall_state(i, False)\n","        #         print(self.__loader.handler.apply(len, save = False))\n","        #         print(self.__loader.handler.apply(type, save = False))\n","        #         self.__loader.handler.apply(lambda ds: SKDatasetHandler.save_data_and_labels([ds, self.__label_converter.convert_label_type(ds.labels), ds.data]))\n","        #         self.__loader.handler.description = \"\".join(desc)\n","        #         # f\"Type {classification}, Unchanged\" # StatAndOth Repressed\"\n","        #         self.__loader.handler.classification = classification\n","        #         self.__loader.handler.log_state(False)\n","        #     else:\n","        #         only_type3 = False\n","        dl_ind_list = list(self.__loader.current_dataloaders)\n","        # add this back in later, and comment out the loop below it (at least for more general situations)\n","        # if only_type3:\n","        #     for i in indices:\n","        #         dl_ind_list[i] += cur_size\n","        # else:\n","        #     for i in indices:\n","        #         dl_ind_list[i] = cur_size * 2 - 1\n","        if not hacky:\n","            _, indices = self.__loader.get_dataloaders(None, \"Test\", True)\n","            # this is still hacky... I had to hack my own hack\n","            for i in indices:\n","                dl_ind_list[i] = (dl_ind_list[i] % 2) + len(self.__loader.handler) - cur_size\n","        dl_ind_list[1] = hacky_tuple.index(classification) * 2\n","        print(f\"Changed active dataloaders from indices {self.__loader.current_dataloaders} to indices {tuple(dl_ind_list)}\")\n","        self.__loader.current_dataloaders = tuple(dl_ind_list)\n","\n","\n","\n","    def load_data(self, file_path, *args, **kwargs):\n","        if args:\n","            repress_classes = args[0]\n","            if len(args) > 1:\n","                args = args[1:]\n","            else:\n","                args = []\n","        else:\n","            repress_classes = kwargs.pop(\"repress_classes\", True)\n","        # self.train_loader = JFSKLoader(file_path, self.sequence_length, repress_classes, *args, **kwargs)\n","        # class_type = self.train_loader.specifier_values[SKDescriptors.CLASSIFICATION_TYPE_FS]\n","        # dataset states 0 and 1\n","        self.__loader = JFSKLoader(file_path, self.sequence_length, repress_classes, True, *args, **kwargs)\n","        class_type = self.__loader.specifier_values[SKDescriptors.CLASSIFICATION_TYPE_FS]\n","        # assertion\n","        SKDescriptors.validate_class_type(class_type)\n","        # needed definitions\n","        self.train_class_type = class_type\n","        if self.__label_converter is None:\n","            self.__label_converter = SKLabelConverter(None, self.__loader.specifier_values)\n","        self.tempfunc_prepare_loader()\n","\n","\n","    def evaluate(self, show_cm = True, save_cm_path = None, feedback = False):\n","        all_preds = []\n","        all_labels = []\n","        correct = 0\n","        total = 0\n","        first_iteration = True\n","\n","        # counter = 0\n","        with torch.no_grad():   # Since we're not training, we don't need to calculate the gradients\n","            # print(self.__loader.handler.apply(lambda ds: np.shape(ds.data), save = False))\n","            for data in self.__loader.select(\"Test\"): # self.get_eval_loader().test_dataloader:\n","                inputs, labels = data\n","                outputs = SKJFModel.get_outputs(self, inputs, feedback and first_iteration)\n","                # if self.train_class_type != self.get_eval_class_type():\n","                #     # torch.Tensor, \n","                #     outputs = self.__label_converter.convert_label_type(outputs, False, False, True, first_iteration)\n","                _, predicted = torch.max(outputs.data, 1)\n","                if self.train_class_type != self.get_eval_class_type():\n","                    # torch.Tensor, \n","                    predicted = self.__label_converter.convert_label_type(predicted, True, False, True, first_iteration)\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_labels.extend(labels.cpu().numpy())\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","                # if feedback and counter % 10 == 0:\n","                #     print(\"click\")\n","                #     print(predicted.cpu().numpy())\n","                #     print(labels.cpu().numpy())\n","                # counter += 1\n","                if first_iteration:\n","                    first_iteration = False\n","\n","        print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))\n","        \n","        # self.jfm_plot_confusion_matrix(show_cm)\n","        if not show_cm and save_cm_path is None:\n","            return\n","        class_names = SKDescriptors.CTS_PER_TYPE[self.get_eval_class_type()] # [str(c) for c in SKDescriptors.CTS_PER_TYPE[self.class_type]]\n","        cm = confusion_matrix(all_labels, all_preds)\n","\n","        fig, ax = plt.subplots(figsize=(10, 10))\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","        plt.ylabel('Actual')\n","        plt.xlabel('Predicted')\n","        plt.title('Confusion Matrix')\n","        # saving needs to occur first, else we'll be left with a blank image\n","        if save_cm_path is not None:\n","            plt.savefig(save_cm_path)\n","        if show_cm:\n","            plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
