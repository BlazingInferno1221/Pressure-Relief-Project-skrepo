{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17963,"status":"ok","timestamp":1716579210642,"user":{"displayName":"Stephen Ketola","userId":"11844316096403388973"},"user_tz":300},"id":"shze7mRvF4UG","outputId":"c76c2557-ca9f-46a6-b92d-bcf1117312da"},"outputs":[{"name":"stdout","output_type":"stream","text":["__main__\n","Mounted at /content/drive\n","/content/drive/MyDrive/PressureReliefWorkArea/SummerWork\n","AbstractModel.ipynb  DataProcessing.ipynb   RunAndEvaluation.ipynb\n","CNNModel.ipynb\t     HelperFunctions.ipynb\n"]}],"source":["# # no need for this since it has nothing outside classes and functions\n","# print(__name__)\n","# if __name__ == \"__main__\" and hasattr(__builtins__,'__IPYTHON__') and ('google.colab' in str(get_ipython())):\n","#     from google.colab import drive\n","#     drive.mount('/content/drive')\n","#     %cd /content/drive/MyDrive/PressureReliefWorkArea/SummerWork/\n","#     !ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymrhYFKhF3l4"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","%run -n AbstractModel.ipynb"]},{"cell_type":"markdown","metadata":{"id":"muMQxfupF3l6"},"source":["In this code, we added 2 more convolutional layers, which can extract more complex features from your accelerometer data. The number of output channels in the convolutional layers gradually increases, as it is common in many deep learning models to gradually increase the complexity and decrease the spatial size.\n","\n","Please note that the dimension of the input to the fully connected layer depends on the output size of your last convolutional layer. This code assumes that after 3 layers of convolution with kernel size 5 and stride 1, the sequence length is reduced to 82 (from the original 100). You may need to adjust this according to your own situation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2TBKxZr1n3V"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self, class_type, sequence_length):\n","        super(Net, self).__init__()\n","        # the actual net parts were moved into the following function\n","            # since we need additional information before setup\n","\n","    # def init_net(self):\n","        input_num = SKDescriptors.NUM_OF_INPUTS_PER_TYPE[class_type]\n","        class_num = SKDescriptors.NUM_OF_CLASSES_PER_TYPE[class_type]\n","\n","        self.conv1 = nn.Conv1d(input_num, 64, kernel_size=3)\n","        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)\n","        self.conv3 = nn.Conv1d(128, 256, kernel_size=3)\n","\n","        # Adjust the fully connected layer's input size based on the new sequence length after convolutions.\n","        # Adjusted for sequence length = 4 after 3 conv layers with kernel size 3\n","        # 10 -3 + 1 = 8 after the first layer\n","        # 8 - 3 + 1 = 6 after the second layer\n","        # 6 - 3 + 1 = 4 after the third layer\n","        self.fc1 = nn.Linear(256 * (sequence_length - 6), 128)  # Adjusted for sequence length = 4 after 3 conv layers with kernel size 3\n","        self.fc2 = nn.Linear(128, class_num)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.relu(self.conv3(x))\n","        x = x.view(-1, self.num_flat_features(x))  # Flatten the tensor\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)  # Apply softmax to the output layer\n","\n","    def num_flat_features(self, x):\n","        size = x.size()[1:]  # All dimensions except the batch dimension\n","        num_features = 1\n","        for s in size:\n","            num_features *= s\n","        return num_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sz9PYt1fF3l7"},"outputs":[],"source":["class JFNetModel(SKJFModel):\n","    def __init__(self, sequence_length = 10):\n","        # this should get sent to SKJFModel first, which needs sequence_length,\n","            # and which then calls super().__init__() with no arguments,\n","            # which should be sent to nn.Module's __init__()\n","        super(JFNetModel, self).__init__(sequence_length)\n","        # self.sequence_length = sequence_length\n","        self.net = None\n","\n","\n","    def get_outputs(self, inputs, feedback = False):\n","        return self.net(inputs)\n","\n","\n","    # def skm_load_data(self, file_path):\n","    #     # super(JFSKNetModel, self).skm_load_data(file_path)\n","    #     SKJFModel.skm_load_data(self, file_path)\n","    \n","    def load_model(self, file_path = None, class_type = None):\n","        if class_type is not None:\n","            self.train_class_type = class_type\n","        if file_path is None:\n","            self.net = Net(self.train_class_type, self.sequence_length)\n","            return\n","        \n","        match SKFileNameHandler.read_file_extension(file_path):\n","            case '.pth':\n","                self.net = torch.load(file_path)\n","            case _:\n","                raise NotImplementedError(f\"JFNetModel.load_model() is not equipped to open {_} files.\")\n","\n","\n","# still working on this\n","    def train(self, save_file_path, epochs = 1000, feedback = False):\n","        # Instantiate the network and optimizer\n","        if self.net is None:\n","            self.load_model()\n","        optimizer = optim.SGD(self.net.parameters(), lr=0.01)\n","\n","        # Define the loss function\n","        criterion = nn.CrossEntropyLoss()\n","\n","        # Assume we have a data loader `train_dataloader` which loads our training accelerometer data\n","        for epoch in range(epochs + 1):  # loop over the dataset multiple times\n","\n","            running_loss = 0.0\n","            # for i, data in enumerate(self.get_loader().select(\"Train\"), 0): # enumerate(self.train_loader.train_dataloader, 0):\n","            #     print(i)\n","            #     print(data)\n","            for i, data in enumerate(self.get_loader().select(\"Train\"), 0): # enumerate(self.train_loader.train_dataloader, 0):\n","            # for i, *args in enumerate(self.get_loader().select(\"Train\"), 0): # enumerate(self.train_loader.train_dataloader, 0):\n","            #     # get the inputs; data is a list of [inputs, labels]\n","            #     print(args)\n","            #     if len(args) != 1:\n","            #         print(len(args))\n","            #         raise Exception(\"yippee\")\n","            #     data = args[0]\n","                inputs, labels = data\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward + backward + optimize\n","                outputs = self.net(inputs)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","\n","                # print statistics\n","                running_loss += loss.item()\n","                if (epoch % 200) == 0:    # print every 2000 mini-batches\n","                    if feedback or not i:\n","                        print('[%d, %5d] loss: %.3f' %\n","                            (epoch + 1, i + 1, running_loss / 2000))\n","                    running_loss = 0.0\n","\n","        print('Finished Training')\n","\n","        # Now we will validate the model using test data\n","        correct = 0\n","        total = 0\n","\n","        with torch.no_grad():   # Since we're not training, we don't need to calculate the gradients\n","            for data in self.get_loader().select(\"Test\"): # self.train_loader.test_dataloader:\n","                inputs, labels = data\n","                outputs = self.net(inputs)\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))\n","\n","\n","        # Saving the entire model\n","\n","        torch.save(self.net, save_file_path)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
