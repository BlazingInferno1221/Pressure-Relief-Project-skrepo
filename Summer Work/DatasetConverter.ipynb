{"cells":[{"cell_type":"code","source":["print(__name__)\n","if __name__ == \"__main__\" and hasattr(__builtins__,'__IPYTHON__') and ('google.colab' in str(get_ipython())):\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd /content/drive/MyDrive/PressureReliefWorkArea/SummerWork/\n","    !ls"],"metadata":{"id":"bZLKiFqtPRNs"},"id":"bZLKiFqtPRNs","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"b20374ca","metadata":{"id":"b20374ca"},"outputs":[],"source":["import pandas as pd\n","# from sklearn.model_selection import train_test_split\n","# from torch.utils.data import Dataset, DataLoader\n","# import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","# import torch.optim as optim\n","import numpy as np\n","\n","%run -n HelperFunctions.ipynb\n","# import ipynb\n","# from ipynb.fs.full.HelperFunctions import *"]},{"cell_type":"code","source":["class SKConverter:\n","\n","    VALID_TYPE_CONVERSIONS = (\n","        (3, 5),\n","    )\n","    OVERRIDE_TYPE_VALIDATION = (\n","        # This is here only for conversions that\n","            # fail validate_class_type_conversion() but not for simple reasons\n","            # (simple reasons like accidentally choosing the wrong input/output types\n","            # or not listing the correct values in the below dictionaries)\n","        # If you add an entry here you may have to change logic of other parts of the code\n","            # for instance if the number of columns of the output spreadsheet will be more\n","            # than the input spreadsheet, you may have to change the dataframe.drop line at the end\n","    )\n","\n","\n","\n","    # Currently these do nothing. If we later change how we want the buffers to function\n","        # (not the length of the buffers but which buffers overlap into other classes),\n","        # we will be able to do so using this\n","    VALID_BUFFER_TYPE_CONVERSIONS = ()\n","    OVERRIDE_BUFFER_TYPE_VALIDATION = (\n","        # This is here only for BufferType conversions that\n","            # fail validate_buffer_type_conversion() but not for simple reasons\n","            # (simple reasons like accidentally choosing the wrong input/output types\n","            # or not listing the correct values in the above dictionaries)\n","        # If you add an entry here you may have to change logic of other parts of the code\n","    )\n","\n","\n","\n","    def __init__(self, labeled_data_file):\n","        # if not all(n == Converter.NUM_OF_LABEL_TYPES for n in (len(Converter.NUM_OF_INPUTS_PER_TYPE), len(Converter.NUM_OF_CLASSES_PER_TYPE), len(Converter.NUM_OF_OUTPUTS_PER_TYPE))):\n","        #     print(\"Converter is not usable if defining dictionaries do not match corresponding dictionaries in size.\")\n","        #     print(\"Fix and rerun the code to use the converter\")\n","        #     return\n","        self.input_directory, self.input_beginning_descriptors, self.input_file_name, self.input_ending_descriptors, self.input_file_extension, self.input_specifiers = SKFileNameHandler.read_data_file_name(labeled_data_file)\n","        self.output_label_type = -1\n","        self.output_freq = -1\n","        self.output_buffer_type = -1\n","        self.output_buffer_num = -1\n","\n","\n","\n","    def validate_label_type_conversion(self, input_label_type, output_label_type):\n","        # validating type values' consistency\n","        has_valid_types = SKDescriptors.validate_class_type(input_label_type) and SKDescriptors.validate_class_type(output_label_type)\n","        # input_label_type matches self.input_label_type\n","        matches_input_file = self.input_specifiers.get(SKDescriptors.CLASSIFICATION_TYPE_FS, -1) == input_label_type\n","        # input_label_type corresponds to WithClassNum value stored in self\n","        consistent_with_class_num = self.input_specifiers.get(SKDescriptors.WITH_CLASS_NUMBER_FS, -1) == SKDescriptors.NUM_OF_CLASSES_PER_TYPE[input_label_type]\n","        # has valid values (compared to type dictionaries and the conversion file)\n","        has_consistent_values = has_valid_types and matches_input_file and consistent_with_class_num\n","\n","        # validating conversion logic\n","        # is a type conversion for which someone implemented the logic\n","        is_listed = (input_label_type, output_label_type) in SKConverter.VALID_TYPE_CONVERSIONS #.get((input_label_type, output_label_type), False)\n","        # is a logical input type conversion\n","        is_not_to_more_inputs = SKDescriptors.NUM_OF_INPUTS_PER_TYPE.get(input_label_type, 0) >= SKDescriptors.NUM_OF_INPUTS_PER_TYPE.get(output_label_type, 1)\n","        # is a logical output type conversion when only one class chosen at a time\n","        is_to_fewer_classes = SKDescriptors.NUM_OF_CLASSES_PER_TYPE.get(input_label_type, 0) > SKDescriptors.NUM_OF_CLASSES_PER_TYPE.get(output_label_type, 0)\n","        # may be logical output type conversion if we are converting from\n","            # an output with a \"multi-hot\" vector to an input with a one-hot vector\n","        input_is_not_one_hot_type = SKDescriptors.NUM_OF_OUTPUTS_PER_TYPE.get(input_label_type, 1) != 1\n","        # all conversion logic between types is sound\n","        has_valid_logic = is_listed and is_not_to_more_inputs and (is_to_fewer_classes or input_is_not_one_hot_type)\n","\n","        # allowing override\n","        # the others are to keep someone from accidentally making a \"bad conversion,\"\n","            # but this one is to allow more-complex conversions that are possible,\n","            # given that someone manually listed the conversion in OVERRIDE_TYPE_VALIDATION\n","        # this does not override the conversion if the file is incorrect or if the types are invalid\n","        is_overridden = (input_label_type, output_label_type) in SKConverter.OVERRIDE_TYPE_VALIDATION #.get((input_label_type, output_label_type), False)\n","\n","        return has_consistent_values and (has_valid_logic or is_overridden)\n","\n","\n","    def validate_buffer_num_conversion(self, input_buffer_num, output_buffer_num):\n","        # validate consistency\n","        # both buffer nums are non-negative\n","        has_nonnegative_buffer_nums = input_buffer_num >= 0 and output_buffer_num >= 0\n","        # input_buffer_num matches self.input_buffer_num\n","        matches_input_file = self.input_specifiers.get(SKDescriptors.BUFFER_NUMBER_FS, -1) == input_buffer_num\n","        # BufferType is valid\n","        has_valid_buffer_type = self.input_specifiers.get(SKDescriptors.BUFFER_TYPE_FS, 0) in np.arange(1, SKDescriptors.NUM_OF_BUFFER_TYPES + 1)\n","        # combining\n","        has_consistent_values = has_nonnegative_buffer_nums and matches_input_file and has_valid_buffer_type\n","        # returning\n","        return has_consistent_values\n","\n","\n","    def set_label_type_conversion(self, input_label_type, output_label_type):\n","        #NOTE that types have not yet been implemented as tuple labels\n","        if(not self.validate_label_type_conversion(input_label_type, output_label_type)):\n","            print(f\"Current object/class definitions prohibit the conversion from Type {input_label_type} to Type {output_label_type}.\")\n","            return\n","        #self.input_label_type = input_label_type\n","        self.output_label_type = output_label_type\n","\n","\n","    def set_buffer_num_conversion(self, input_buffer_num, output_buffer_num):\n","        if(not self.validate_buffer_num_conversion(input_buffer_num, output_buffer_num)):\n","            print(f\"Current object/class definitions prohibit the conversion from BufferNum {input_buffer_num} to BufferNum {output_buffer_num}.\")\n","            return\n","        #self.input_buffer_num = input_buffer_num\n","        self.output_buffer_num = output_buffer_num\n","\n","\n","\n","\n","    # You will VERY LIKELY have to manually check the last column and fix any mismatches in the rows with 1's\n","        # DO NOT delete the last column if you don't know what it is there for\n","        # (it is to mark which rows the converter skipped since otherwise there might be inconsistencies.\n","        # that way, you can manually change it how you had in mind)\n","    def convert_buffer_num(self, output_folder_path='_', return_df=False, override_output_file_path=False):\n","        if(not self.validate_buffer_num_conversion(self.input_specifiers['BufferNum'], self.output_buffer_num)):\n","            print(f\"Current object/class definitions prohibit the conversion from BufferNum {self.input_specifiers['BufferNum']} to BufferNum {self.output_buffer_num}.\")\n","            return\n","        if (not return_df) and output_folder_path == '_':\n","            output_folder_path = self.input_directory\n","\n","        num_of_inputs = Converter.NUM_OF_INPUTS_PER_TYPE[self.input_specifiers['Type']]\n","\n","        input_dataframe = pd.read_csv(self.input_directory + self.input_file_name, header=None)\n","        input_df_length = input_dataframe.shape[0]\n","        manual_override_required_at = pd.DataFrame(np.zeros((input_df_length,1)), columns = pd.Index([input_dataframe.shape[1]], dtype='int64'))\n","        output_dataframe = input_dataframe.join(manual_override_required_at)\n","\n","        next_class = None\n","        i = 0\n","        while(i < input_df_length):\n","            prev_class = next_class\n","            # This line takes a row and focuses on the labels\n","                # I do want it to crash if the dictionary cannot pull the value at the given index\n","            next_class = input_dataframe[i, np.where(input_dataframe[i, num_of_inputs : input_dataframe.shape[1]]) + num_of_inputs]\n","\n","\n","        if(return_df):\n","            return output_dataframe\n","        # else create spreadsheet\n","        # if you want to override the output_file_path, please do so through the function arguments\n","        if(override_output_file_path):\n","            output_file_path = output_folder_path\n","        else:\n","            output_file_path = output_folder_path + Converter.build_file_name(output_file_specifiers, self.input_beginning_descriptors, self.input_ending_descriptors, self.input_file_extension) # You are too far to the right; go back to the left\n","            # outdated version:\n","            # f\"{output_folder_path}COMBINED_Type{self.output_label_type}-WithClassNum{Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]}-Freq10-Buffer{output_buffer_number}-Labeled_Motion-sessions_23-24_Fall.csv\"\n","\n","        dataframe.to_csv(output_file_path, mode='x')\n","\n","\n","\n","    # output_folder_path should end with a '/'\n","    # if you want to override the output_file_path, please do so through output_folder_path (with override = True)\n","    def convert_label_type(self, output_folder_path='_', return_df=False, override_output_file_path=False):\n","        if(not self.validate_label_type_conversion(self.input_specifiers['Type'], self.output_label_type)):\n","            print(f\"Current object/class definitions prohibit the conversion from Type {self.input_specifiers['Type']} to Type {self.output_label_type}.\")\n","            return\n","        if (not return_df) and output_folder_path == '_':\n","            output_folder_path = self.input_directory\n","\n","        input_dataframe = pd.read_csv(self.input_directory + self.input_file_name, header=None)\n","        #input_input_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.input_label_type]\n","        # input_total_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.input_label_type] + Converter.NUM_OF_CLASSES_PER_TYPE[self.input_label_type]\n","        #output_input_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.output_label_type]\n","        # output_total_columns = Converter.NUM_OF_INPUTS_PER_TYPE[self.output_label_type] + Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]\n","        print(input_dataframe.columns)\n","        #row,\n","        print(input_dataframe.iat[1,1])\n","        print(input_dataframe.at[1,2])\n","\n","\n","        # main conversion logic\n","        match (self.input_specifiers['Type'], self.output_label_type):\n","\n","            # We will mainly want to use stuff like df.iloc[[0, 2], [1, 3]] to access rows/columns\n","\n","            case (3, 5):\n","                if(not self.validate_label_type_conversion(3, 5)):\n","                    print(\"Current class definitions prohibit the conversion from Type 3 to Type 5.\")\n","                    return\n","\n","                input_df_length = input_dataframe.shape[0]\n","                output_dataframe = input_dataframe.iloc[0:input_df_length,0:3]\n","                #df.set_index('key').join(other.set_index('key'))\n","\n","                # We're mapping (with +3 columns for input):\n","                    # FKS (1) and FTS (3) to FS (1)\n","                    # FKE (2) and FTE (4) to FE (2)\n","                    # LPS (5), LHS (7), RPS (9), and RHS (11) to LS (3)\n","                    # LPE (6), LHE (8), RPE (10), and RHE (12) to LE (4)\n","                    # PS (13) to PS (5)\n","                    # PE (14) to PE (6)\n","                    # S (15) to S (7)\n","                    # O (16) to O (8)\n","\n","                #add 2 to all indexes since 3 input columns\n","                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[3,5]].sum(axis=1))\n","                temp_df.columns = pd.Index([3], dtype='int64')\n","                # print(temp_df.columns)\n","                output_dataframe = output_dataframe.join(temp_df) # (1)\n","\n","                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[4,6]].sum(axis=1))\n","                temp_df.columns = pd.Index([4], dtype='int64')\n","                output_dataframe = output_dataframe.join(temp_df) # (2)\n","\n","                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[7,9,11,13]].sum(axis=1))\n","                temp_df.columns = pd.Index([5], dtype='int64')\n","                output_dataframe = output_dataframe.join(temp_df) # (3)\n","\n","                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length,[8,10,12,14]].sum(axis=1))\n","                temp_df.columns = pd.Index([6], dtype='int64')\n","                output_dataframe = output_dataframe.join(temp_df) # (4)\n","\n","                temp_df = pd.DataFrame(input_dataframe.iloc[0:input_df_length, 15:19])\n","                temp_df.columns = pd.Index([7,8,9,10], dtype='int64')\n","                output_dataframe = output_dataframe.join(temp_df) # (5:8)\n","\n","\n","            case _ :\n","                print(f\"Logic not implemented for conversion from Type {self.input_specifiers['Type']} to Type {self.output_label_type}.\")\n","                return\n","\n","        if return_df:\n","            return output_dataframe\n","        # else create spreadsheet\n","        # if you want to override the output_file_path, please do so through the function arguments\n","        if(override_output_file_path):\n","            output_file_path = output_folder_path\n","        else:\n","            output_file_specifiers = self.input_specifiers\n","            output_file_specifiers['Type'] = self.output_label_type\n","            output_file_specifiers['WithClassNum'] = Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]\n","            print(\"If these are the same, you've modified the input file specifiers (which is not necessarily terrible):\\n\", self.input_specifiers['Type'], output_file_specifiers['Type'])\n","            output_file_path = output_folder_path + Converter.build_file_name(output_file_specifiers, self.input_beginning_descriptors, self.input_ending_descriptors, self.input_file_extension)\n","        # next two comments are old things\n","        # f\"{output_folder_path}COMBINED_Type{self.output_label_type}-WithClassNum{Converter.NUM_OF_CLASSES_PER_TYPE[self.output_label_type]}-Freq10-Labeled_Motion-sessions_23-24_Fall.csv\"\n","        # output_dataframe.drop(np.arange(output_total_columns, input_total_columns), axis=1)\n","        # file names should, starting now, include the number of classes the type has\n","        # \"‘x’, exclusive creation, failing if the file already exists.\" (quote from https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n","        output_dataframe.to_csv(output_file_path, mode='x')"],"metadata":{"id":"Ooiw8Dwbtf2r"},"id":"Ooiw8Dwbtf2r","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}